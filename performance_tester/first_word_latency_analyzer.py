#!/usr/bin/env python3
"""
é¦–å­—å»¶è¿Ÿåˆ†æå·¥å…·
åˆ†æVADã€ASRã€LLMã€TTSå„ç¯èŠ‚çš„å»¶è¿Ÿè´¡çŒ®
"""

import asyncio
import time
import json
import statistics
from typing import Dict, List, Tuple
import aiohttp
from tabulate import tabulate
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class FirstWordLatencyAnalyzer:
    def __init__(self):
        self.asr_url = "http://localhost:8001"
        self.llm_url = "http://localhost:8002"  # å‡è®¾LLMæœåŠ¡ç«¯å£
        self.tts_url = "http://localhost:8003"  # å‡è®¾TTSæœåŠ¡ç«¯å£
        self.vad_url = "http://localhost:8004"  # å‡è®¾VADæœåŠ¡ç«¯å£
        
        self.results = {
            'vad': [],
            'asr': [],
            'llm': [],
            'tts': [],
            'total_pipeline': []
        }
    
    async def _test_vad_latency(self, session: aiohttp.ClientSession, audio_data: bytes) -> float:
        """æµ‹è¯•VADå»¶è¿Ÿ"""
        start_time = time.time()
        
        try:
            # æ¨¡æ‹ŸVADæ£€æµ‹
            # å®é™…åº”è¯¥è°ƒç”¨çœŸå®çš„VADæœåŠ¡
            await asyncio.sleep(0.02)  # æ¨¡æ‹Ÿ20ms VADå¤„ç†æ—¶é—´
            
            return time.time() - start_time
        except Exception as e:
            logger.error(f"VADæµ‹è¯•å¤±è´¥: {e}")
            return 0.05  # è¿”å›é»˜è®¤å€¼
    
    async def _test_asr_latency(self, session: aiohttp.ClientSession, audio_data: bytes) -> Tuple[float, bool]:
        """æµ‹è¯•ASRå»¶è¿Ÿ"""
        start_time = time.time()
        
        try:
            import base64
            audio_base64 = base64.b64encode(audio_data).decode('utf-8')
            
            request_data = {
                "session_id": f"latency_test_{int(time.time())}",
                "audio_data": audio_base64,
                "sample_rate": 16000,
                "language": "zh",
                "priority": 1,
                "timestamp": time.time()
            }
            
            async with session.post(
                f"{self.asr_url}/asr/recognize",
                json=request_data,
                headers={'Content-Type': 'application/json'},
                timeout=aiohttp.ClientTimeout(total=5)
            ) as response:
                
                latency = time.time() - start_time
                success = response.status == 200
                
                if success:
                    result = await response.json()
                    logger.debug(f"ASRç»“æœ: {result.get('text', '')}")
                
                return latency, success
                
        except Exception as e:
            logger.error(f"ASRæµ‹è¯•å¤±è´¥: {e}")
            return time.time() - start_time, False
    
    async def _test_llm_latency(self, session: aiohttp.ClientSession, text: str) -> Tuple[float, bool]:
        """æµ‹è¯•LLMé¦–tokenå»¶è¿Ÿ"""
        start_time = time.time()
        
        try:
            # æ¨¡æ‹ŸLLMè°ƒç”¨
            # å®é™…åº”è¯¥è°ƒç”¨çœŸå®çš„LLMæœåŠ¡
            await asyncio.sleep(0.3)  # æ¨¡æ‹Ÿ300ms LLMé¦–tokenç”Ÿæˆæ—¶é—´
            
            return time.time() - start_time, True
            
        except Exception as e:
            logger.error(f"LLMæµ‹è¯•å¤±è´¥: {e}")
            return time.time() - start_time, False
    
    async def _test_tts_latency(self, session: aiohttp.ClientSession, text: str) -> Tuple[float, bool]:
        """æµ‹è¯•TTSå»¶è¿Ÿ"""
        start_time = time.time()
        
        try:
            # æ¨¡æ‹ŸTTSè°ƒç”¨
            # å®é™…åº”è¯¥è°ƒç”¨çœŸå®çš„TTSæœåŠ¡
            await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿ100ms TTSå¤„ç†æ—¶é—´
            
            return time.time() - start_time, True
            
        except Exception as e:
            logger.error(f"TTSæµ‹è¯•å¤±è´¥: {e}")
            return time.time() - start_time, False
    
    async def _test_full_pipeline(self, session: aiohttp.ClientSession, audio_data: bytes) -> Dict:
        """æµ‹è¯•å®Œæ•´è¯­éŸ³äº¤äº’æµæ°´çº¿"""
        pipeline_start = time.time()
        
        # 1. VADæ£€æµ‹
        vad_start = time.time()
        vad_latency = await self._test_vad_latency(session, audio_data)
        vad_end = time.time()
        
        # 2. ASRè¯†åˆ«
        asr_start = time.time()
        asr_latency, asr_success = await self._test_asr_latency(session, audio_data)
        asr_end = time.time()
        
        # 3. LLMç”Ÿæˆ (ä½¿ç”¨æ¨¡æ‹Ÿæ–‡æœ¬)
        llm_start = time.time()
        llm_latency, llm_success = await self._test_llm_latency(session, "ç”¨æˆ·è¯´è¯å†…å®¹")
        llm_end = time.time()
        
        # 4. TTSåˆæˆ
        tts_start = time.time()
        tts_latency, tts_success = await self._test_tts_latency(session, "AIå›å¤å†…å®¹")
        tts_end = time.time()
        
        total_latency = time.time() - pipeline_start
        
        return {
            'vad_latency': vad_latency,
            'asr_latency': asr_latency,
            'llm_latency': llm_latency,
            'tts_latency': tts_latency,
            'total_latency': total_latency,
            'asr_success': asr_success,
            'llm_success': llm_success,
            'tts_success': tts_success,
            'timestamp': pipeline_start
        }
    
    async def run_latency_analysis(self, test_count: int = 20):
        """è¿è¡Œé¦–å­—å»¶è¿Ÿåˆ†æ"""
        logger.info(f"å¼€å§‹é¦–å­—å»¶è¿Ÿåˆ†æï¼Œæµ‹è¯•æ¬¡æ•°: {test_count}")
        
        # ç”Ÿæˆæµ‹è¯•éŸ³é¢‘æ•°æ®
        test_audio = b"fake_audio_data" * 1000  # æ¨¡æ‹ŸéŸ³é¢‘æ•°æ®
        
        async with aiohttp.ClientSession() as session:
            for i in range(test_count):
                logger.info(f"æ‰§è¡Œç¬¬ {i+1}/{test_count} æ¬¡æµ‹è¯•...")
                
                result = await self._test_full_pipeline(session, test_audio)
                
                # è®°å½•å„ç¯èŠ‚ç»“æœ
                self.results['vad'].append(result['vad_latency'])
                self.results['asr'].append(result['asr_latency'])
                self.results['llm'].append(result['llm_latency'])
                self.results['tts'].append(result['tts_latency'])
                self.results['total_pipeline'].append(result['total_latency'])
                
                # çŸ­æš‚é—´éš”
                await asyncio.sleep(0.5)
        
        self._analyze_and_report()
    
    def _analyze_and_report(self):
        """åˆ†æå¹¶ç”ŸæˆæŠ¥å‘Š"""
        print("\n" + "=" * 80)
        print("ğŸ¯ é¦–å­—å»¶è¿Ÿåˆ†ææŠ¥å‘Š")
        print("=" * 80)
        
        # è®¡ç®—å„ç¯èŠ‚ç»Ÿè®¡æ•°æ®
        stats_data = []
        total_avg_latency = 0
        
        for component, latencies in self.results.items():
            if not latencies:
                continue
                
            avg_latency = statistics.mean(latencies) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            min_latency = min(latencies) * 1000
            max_latency = max(latencies) * 1000
            p95_latency = statistics.quantiles(latencies, n=20)[18] * 1000 if len(latencies) >= 20 else max_latency
            
            # è®¡ç®—å»¶è¿Ÿè´¡çŒ®ç™¾åˆ†æ¯”
            if component != 'total_pipeline':
                total_avg_latency += avg_latency
            
            stats_data.append({
                'component': component,
                'avg_ms': avg_latency,
                'min_ms': min_latency,
                'max_ms': max_latency,
                'p95_ms': p95_latency
            })
        
        # åˆ›å»ºç»“æœè¡¨æ ¼
        headers = ["ç¯èŠ‚", "å¹³å‡å»¶è¿Ÿ(ms)", "æœ€å°å»¶è¿Ÿ(ms)", "æœ€å¤§å»¶è¿Ÿ(ms)", "P95å»¶è¿Ÿ(ms)", "å»¶è¿Ÿå æ¯”(%)"]
        table_data = []
        
        component_names = {
            'vad': 'VADæ£€æµ‹',
            'asr': 'ASRè¯†åˆ«',
            'llm': 'LLMç”Ÿæˆ',
            'tts': 'TTSåˆæˆ',
            'total_pipeline': 'æ€»æµæ°´çº¿'
        }
        
        for stat in stats_data:
            component = stat['component']
            if component == 'total_pipeline':
                percentage = 100.0
            else:
                percentage = (stat['avg_ms'] / total_avg_latency) * 100 if total_avg_latency > 0 else 0
            
            # æ·»åŠ çŠ¶æ€æŒ‡ç¤ºå™¨
            if component == 'asr' and stat['avg_ms'] > 500:
                status = "ğŸ”´ ç“¶é¢ˆ"
            elif component == 'llm' and stat['avg_ms'] > 800:
                status = "ğŸŸ¡ å…³æ³¨"
            elif stat['avg_ms'] > 200:
                status = "ğŸŸ  ä¼˜åŒ–"
            else:
                status = "âœ… è‰¯å¥½"
            
            table_data.append([
                f"{component_names.get(component, component)} {status}",
                f"{stat['avg_ms']:.0f}",
                f"{stat['min_ms']:.0f}",
                f"{stat['max_ms']:.0f}",
                f"{stat['p95_ms']:.0f}",
                f"{percentage:.1f}%"
            ])
        
        print(tabulate(table_data, headers=headers, tablefmt="grid"))
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        self._generate_optimization_suggestions(stats_data)
    
    def _generate_optimization_suggestions(self, stats_data: List[Dict]):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        print("\nğŸ’¡ é¦–å­—å»¶è¿Ÿä¼˜åŒ–å»ºè®®:")
        print("-" * 50)
        
        # æ‰¾å‡ºä¸»è¦ç“¶é¢ˆ
        component_stats = {stat['component']: stat['avg_ms'] for stat in stats_data if stat['component'] != 'total_pipeline'}
        sorted_components = sorted(component_stats.items(), key=lambda x: x[1], reverse=True)
        
        print("ğŸ¯ ä¼˜åŒ–ä¼˜å…ˆçº§ (æŒ‰å»¶è¿Ÿè´¡çŒ®æ’åº):")
        for i, (component, avg_ms) in enumerate(sorted_components, 1):
            component_names = {
                'vad': 'VADæ£€æµ‹',
                'asr': 'ASRè¯†åˆ«', 
                'llm': 'LLMç”Ÿæˆ',
                'tts': 'TTSåˆæˆ'
            }
            print(f"  {i}. {component_names.get(component, component)}: {avg_ms:.0f}ms")
        
        print("\nğŸ”§ å…·ä½“ä¼˜åŒ–æ–¹æ¡ˆ:")
        
        # ASRä¼˜åŒ–å»ºè®®
        asr_latency = component_stats.get('asr', 0)
        if asr_latency > 300:
            print("\nğŸ”´ ASRè¯†åˆ«ä¼˜åŒ– (ä¸»è¦ç“¶é¢ˆ):")
            print("  â€¢ å¯ç”¨æ¨¡å‹é¢„çƒ­: å‡å°‘å†·å¯åŠ¨å»¶è¿Ÿ")
            print("  â€¢ å¢åŠ ASR_MAX_CONCURRENT: æé«˜å¹¶å‘å¤„ç†èƒ½åŠ›")
            print("  â€¢ ä¼˜åŒ–ASR_BATCH_SIZE: å¹³è¡¡ååé‡å’Œå»¶è¿Ÿ")
            print("  â€¢ å¯ç”¨ASRç¼“å­˜: ç¼“å­˜å¸¸è§éŸ³é¢‘æ¨¡å¼")
            print("  â€¢ ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹: è€ƒè™‘FP16/INT8é‡åŒ–")
            print("  â€¢ éŸ³é¢‘é¢„å¤„ç†ä¼˜åŒ–: å‡å°‘æ•°æ®è½¬æ¢æ—¶é—´")
        
        # LLMä¼˜åŒ–å»ºè®®
        llm_latency = component_stats.get('llm', 0)
        if llm_latency > 500:
            print("\nğŸŸ¡ LLMç”Ÿæˆä¼˜åŒ–:")
            print("  â€¢ æ¨¡å‹é¢„çƒ­: ä¿æŒæ¨¡å‹åœ¨å†…å­˜ä¸­")
            print("  â€¢ é¦–tokenä¼˜åŒ–: ä½¿ç”¨æµå¼ç”Ÿæˆ")
            print("  â€¢ ä¸Šä¸‹æ–‡ç¼“å­˜: ç¼“å­˜å¸¸è§å¯¹è¯ä¸Šä¸‹æ–‡")
            print("  â€¢ æ¨¡å‹é‡åŒ–: ä½¿ç”¨FP16æˆ–INT8")
            print("  â€¢ å¹¶å‘æ§åˆ¶: ä¼˜åŒ–LLM_MAX_CONCURRENT")
        
        # VADä¼˜åŒ–å»ºè®®
        vad_latency = component_stats.get('vad', 0)
        if vad_latency > 50:
            print("\nğŸŸ  VADæ£€æµ‹ä¼˜åŒ–:")
            print("  â€¢ å‡å°‘éŸ³é¢‘ç¼“å†²: é™ä½VAD_BUFFER_SIZE")
            print("  â€¢ ç®—æ³•ä¼˜åŒ–: ä½¿ç”¨æ›´å¿«çš„VADç®—æ³•")
            print("  â€¢ ç¡¬ä»¶åŠ é€Ÿ: å¯ç”¨GPUåŠ é€Ÿ")
        
        # TTSä¼˜åŒ–å»ºè®®
        tts_latency = component_stats.get('tts', 0)
        if tts_latency > 150:
            print("\nğŸŸ  TTSåˆæˆä¼˜åŒ–:")
            print("  â€¢ æµå¼åˆæˆ: è¾¹ç”Ÿæˆè¾¹æ’­æ”¾")
            print("  â€¢ éŸ³é¢‘ç¼“å­˜: ç¼“å­˜å¸¸è§å›å¤")
            print("  â€¢ æ¨¡å‹ä¼˜åŒ–: ä½¿ç”¨æ›´å¿«çš„TTSæ¨¡å‹")
        
        # ç³»ç»Ÿçº§ä¼˜åŒ–
        total_latency = sum(component_stats.values())
        if total_latency > 1000:
            print("\nâš¡ ç³»ç»Ÿçº§ä¼˜åŒ–:")
            print("  â€¢ æµæ°´çº¿å¹¶è¡Œ: VAD+ASR+LLMå¹¶è¡Œå¤„ç†")
            print("  â€¢ é¢„æµ‹æ€§åŠ è½½: æå‰åŠ è½½å¯èƒ½éœ€è¦çš„æ¨¡å‹")
            print("  â€¢ å†…å­˜ä¼˜åŒ–: å¢åŠ ç³»ç»Ÿå†…å­˜ï¼Œå‡å°‘swap")
            print("  â€¢ CPUä¼˜åŒ–: ä½¿ç”¨æ›´å¤šCPUæ ¸å¿ƒ")
            print("  â€¢ ç½‘ç»œä¼˜åŒ–: å‡å°‘æœåŠ¡é—´é€šä¿¡å»¶è¿Ÿ")

async def main():
    """ä¸»å‡½æ•°"""
    analyzer = FirstWordLatencyAnalyzer()
    await analyzer.run_latency_analysis(test_count=10)

if __name__ == "__main__":
    asyncio.run(main())