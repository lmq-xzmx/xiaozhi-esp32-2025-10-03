#!/usr/bin/env python3
"""
16GBæœåŠ¡å™¨é«˜å¹¶å‘ASRæ€§èƒ½æµ‹è¯•
æµ‹è¯•80-100å¹¶å‘è¯·æ±‚çš„å¤„ç†èƒ½åŠ›
"""

import asyncio
import aiohttp
import time
import json
import base64
import numpy as np
from typing import List, Dict, Any
import statistics

def generate_test_audio(duration_ms=1000, sample_rate=16000, frequency=440):
    """ç”Ÿæˆæµ‹è¯•éŸ³é¢‘æ•°æ®"""
    samples = int(duration_ms * sample_rate / 1000)
    t = np.linspace(0, duration_ms/1000, samples)
    audio = np.sin(2 * np.pi * frequency * t) * 0.5
    audio_int16 = (audio * 32767).astype(np.int16)
    return audio_int16.tobytes()

async def send_asr_request(session: aiohttp.ClientSession, session_id: str, base_url: str) -> Dict[str, Any]:
    """å‘é€å•ä¸ªASRè¯·æ±‚"""
    try:
        # ç”Ÿæˆæµ‹è¯•éŸ³é¢‘
        audio_bytes = generate_test_audio(1000, frequency=440 + (hash(session_id) % 200))
        audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
        
        request_data = {
            "session_id": session_id,
            "audio_data": audio_b64,
            "sample_rate": 16000,
            "language": "zh",
            "priority": 2,
            "timestamp": time.time()
        }
        
        start_time = time.time()
        async with session.post(f"{base_url}/asr/recognize", json=request_data) as response:
            end_time = time.time()
            
            if response.status == 200:
                result = await response.json()
                return {
                    "success": True,
                    "session_id": session_id,
                    "latency": end_time - start_time,
                    "processing_time": result.get("processing_time", 0),
                    "cached": result.get("cached", False),
                    "text": result.get("text", ""),
                    "confidence": result.get("confidence", 0)
                }
            else:
                return {
                    "success": False,
                    "session_id": session_id,
                    "error": f"HTTP {response.status}",
                    "latency": end_time - start_time
                }
    except Exception as e:
        return {
            "success": False,
            "session_id": session_id,
            "error": str(e),
            "latency": 0
        }

async def concurrent_test(base_url: str, concurrent_count: int, test_name: str) -> Dict[str, Any]:
    """æ‰§è¡Œå¹¶å‘æµ‹è¯•"""
    print(f"\nğŸš€ å¼€å§‹ {test_name} - {concurrent_count}å¹¶å‘æµ‹è¯•")
    
    connector = aiohttp.TCPConnector(limit=200, limit_per_host=200)
    timeout = aiohttp.ClientTimeout(total=30)
    
    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        tasks = []
        for i in range(concurrent_count):
            session_id = f"16gb_test_{concurrent_count}_{i:03d}"
            task = send_asr_request(session, session_id, base_url)
            tasks.append(task)
        
        # æ‰§è¡Œå¹¶å‘æµ‹è¯•
        start_time = time.time()
        results = await asyncio.gather(*tasks, return_exceptions=True)
        end_time = time.time()
        
        # åˆ†æç»“æœ
        successful_results = [r for r in results if isinstance(r, dict) and r.get("success", False)]
        failed_results = [r for r in results if isinstance(r, dict) and not r.get("success", False)]
        exception_results = [r for r in results if isinstance(r, Exception)]
        
        total_duration = end_time - start_time
        success_count = len(successful_results)
        failure_count = len(failed_results) + len(exception_results)
        success_rate = (success_count / concurrent_count) * 100
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        if successful_results:
            latencies = [r["latency"] for r in successful_results]
            processing_times = [r["processing_time"] for r in successful_results]
            
            avg_latency = statistics.mean(latencies)
            p95_latency = statistics.quantiles(latencies, n=20)[18] if len(latencies) > 1 else latencies[0]
            avg_processing_time = statistics.mean(processing_times)
            throughput = success_count / total_duration
            
            cache_hits = sum(1 for r in successful_results if r.get("cached", False))
            cache_hit_rate = (cache_hits / success_count) * 100
        else:
            avg_latency = p95_latency = avg_processing_time = throughput = cache_hit_rate = 0
        
        return {
            "test_name": test_name,
            "concurrent_count": concurrent_count,
            "total_duration": total_duration,
            "success_count": success_count,
            "failure_count": failure_count,
            "success_rate": success_rate,
            "avg_latency": avg_latency,
            "p95_latency": p95_latency,
            "avg_processing_time": avg_processing_time,
            "throughput": throughput,
            "cache_hit_rate": cache_hit_rate,
            "successful_results": successful_results[:5],  # åªä¿ç•™å‰5ä¸ªæˆåŠŸç»“æœä½œä¸ºæ ·æœ¬
            "failed_results": failed_results[:3]  # åªä¿ç•™å‰3ä¸ªå¤±è´¥ç»“æœ
        }

async def main():
    base_url = "http://localhost:8001"
    
    print("ğŸ¯ 16GBæœåŠ¡å™¨ASRé«˜å¹¶å‘æ€§èƒ½æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•é…ç½®
    test_configs = [
        (50, "ä¸­ç­‰å¹¶å‘æµ‹è¯•"),
        (80, "ç›®æ ‡å¹¶å‘æµ‹è¯•"),
        (100, "æé™å¹¶å‘æµ‹è¯•"),
        (120, "è¶…é™å¹¶å‘æµ‹è¯•")
    ]
    
    all_results = []
    
    for concurrent_count, test_name in test_configs:
        try:
            result = await concurrent_test(base_url, concurrent_count, test_name)
            all_results.append(result)
            
            # æ‰“å°æµ‹è¯•ç»“æœ
            print(f"\nğŸ“Š {test_name} ç»“æœ:")
            print(f"   å¹¶å‘æ•°: {result['concurrent_count']}")
            print(f"   æ€»è€—æ—¶: {result['total_duration']:.2f}s")
            print(f"   æˆåŠŸç‡: {result['success_rate']:.1f}% ({result['success_count']}/{result['concurrent_count']})")
            print(f"   å¹³å‡å»¶è¿Ÿ: {result['avg_latency']:.3f}s")
            print(f"   P95å»¶è¿Ÿ: {result['p95_latency']:.3f}s")
            print(f"   å¹³å‡å¤„ç†æ—¶é—´: {result['avg_processing_time']:.3f}s")
            print(f"   ååé‡: {result['throughput']:.1f} req/s")
            print(f"   ç¼“å­˜å‘½ä¸­ç‡: {result['cache_hit_rate']:.1f}%")
            
            if result['failure_count'] > 0:
                print(f"   âš ï¸  å¤±è´¥æ•°: {result['failure_count']}")
                if result['failed_results']:
                    print(f"   å¤±è´¥åŸå› : {result['failed_results'][0].get('error', 'Unknown')}")
            
            # ç­‰å¾…ä¸€ä¸‹å†è¿›è¡Œä¸‹ä¸€ä¸ªæµ‹è¯•
            await asyncio.sleep(2)
            
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    print(f"\nğŸ“ˆ 16GBæœåŠ¡å™¨ASRæ€§èƒ½æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    for result in all_results:
        if result['success_rate'] >= 95:
            status = "âœ… ä¼˜ç§€"
        elif result['success_rate'] >= 80:
            status = "âš ï¸  è‰¯å¥½"
        else:
            status = "âŒ éœ€ä¼˜åŒ–"
        
        print(f"{status} {result['concurrent_count']}å¹¶å‘: "
              f"æˆåŠŸç‡{result['success_rate']:.1f}%, "
              f"ååé‡{result['throughput']:.1f}req/s, "
              f"å»¶è¿Ÿ{result['avg_latency']:.3f}s")
    
    # æ‰¾å‡ºæœ€ä½³æ€§èƒ½ç‚¹
    best_result = max(all_results, key=lambda x: x['throughput'] if x['success_rate'] >= 90 else 0)
    if best_result['success_rate'] >= 90:
        print(f"\nğŸ† æœ€ä½³æ€§èƒ½é…ç½®: {best_result['concurrent_count']}å¹¶å‘")
        print(f"   æ¨èè®¾å¤‡æ”¯æŒæ•°: {int(best_result['concurrent_count'] * 0.8)}-{best_result['concurrent_count']}å°")
        print(f"   é¢„æœŸååé‡: {best_result['throughput']:.1f} req/s")

if __name__ == "__main__":
    asyncio.run(main())