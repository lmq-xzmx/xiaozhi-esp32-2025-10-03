# âš–ï¸ è´Ÿè½½å‡è¡¡ä¼˜åŒ–æŒ‡å— - 4æ ¸8GBç¡¬ä»¶æœ€å¤§åŒ–åˆ©ç”¨

## ğŸ¯ **ç›®æ ‡**
åœ¨4æ ¸8GBç¡¬ä»¶é™åˆ¶ä¸‹ï¼Œé€šè¿‡æ™ºèƒ½è´Ÿè½½å‡è¡¡ç­–ç•¥ï¼Œå°†è®¾å¤‡æ”¯æ’‘èƒ½åŠ›ä»10å°æå‡åˆ°30-50å°ï¼Œæ”¹å–„æ½œåŠ›è¯„ä¼°ä¸º**300-400%**ã€‚

---

## ğŸ“Š **å½“å‰æ€§èƒ½ç“¶é¢ˆåˆ†æ**

### **èµ„æºä½¿ç”¨ç°çŠ¶**

| æœåŠ¡ | CPUä½¿ç”¨ | å†…å­˜ä½¿ç”¨ | ç“¶é¢ˆç±»å‹ | ä¼˜åŒ–æ½œåŠ› |
|------|---------|----------|----------|----------|
| **xiaozhi-esp32-server** | 0.11% | 1.8GB/4GB | å†…å­˜å¯†é›† | â­â­â­â­â­ |
| **xiaozhi-esp32-server-web** | 0.26% | 407MB/768MB | CPUå¯†é›† | â­â­â­â­ |
| **xiaozhi-esp32-server-db** | 3.54% | 489MB/512MB | å†…å­˜ç“¶é¢ˆ | â­â­â­â­â­ |
| **xiaozhi-esp32-server-redis** | 0.68% | 20MB/256MB | è½»è´Ÿè½½ | â­â­â­ |

### **è´Ÿè½½åˆ†å¸ƒé—®é¢˜**
```yaml
current_issues:
  # ä¸»è¦é—®é¢˜
  primary_bottlenecks:
    - "æ•°æ®åº“å†…å­˜ä½¿ç”¨ç‡95% (489MB/512MB)"
    - "ä¸»æœåŠ¡å†…å­˜ä½¿ç”¨ç‡45% (1.8GB/4GB)"
    - "LLM/TTSè¿œç¨‹APIå»¶è¿Ÿ1.5-3ç§’"
    - "å•ç‚¹æ•…éšœé£é™©é«˜"
    
  # èµ„æºæµªè´¹
  resource_waste:
    - "CPUæ€»ä½¿ç”¨ç‡ < 5%ï¼Œå¤§é‡é—²ç½®"
    - "Rediså†…å­˜ä½¿ç”¨ç‡ä»…8%"
    - "ç½‘ç»œå¸¦å®½åˆ©ç”¨ç‡ä½"
    - "ç¼ºä¹æœåŠ¡é—´è´Ÿè½½åˆ†æ‹…"
    
  # æ‰©å±•æ€§é™åˆ¶
  scalability_limits:
    - "æ‰€æœ‰æœåŠ¡è¿è¡Œåœ¨å•æœº"
    - "ç¼ºä¹æ°´å¹³æ‰©å±•èƒ½åŠ›"
    - "æ— æœåŠ¡é™çº§æœºåˆ¶"
    - "ç¼ºä¹æ™ºèƒ½è·¯ç”±"
```

---

## ğŸ—ï¸ **å¤šå±‚è´Ÿè½½å‡è¡¡æ¶æ„**

### **æ¶æ„è®¾è®¡å›¾**

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Nginx Proxy   â”‚ â† å…¥å£è´Ÿè½½å‡è¡¡
                    â”‚   (åå‘ä»£ç†)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  API Gateway    â”‚ â† æ™ºèƒ½è·¯ç”±å±‚
                    â”‚  (è·¯ç”±åˆ†å‘)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                     â”‚                     â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
   â”‚ ASRæœåŠ¡  â”‚         â”‚ LLMæœåŠ¡   â”‚         â”‚ TTSæœåŠ¡   â”‚
   â”‚ å®ä¾‹1-2  â”‚         â”‚ å®ä¾‹1-3   â”‚         â”‚ å®ä¾‹1-2   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                     â”‚                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   å…±äº«å­˜å‚¨å±‚     â”‚
                    â”‚ Redis + MySQL   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **è´Ÿè½½å‡è¡¡ç­–ç•¥é…ç½®**

```yaml
# load_balancing_config.yaml
load_balancing:
  # å…¨å±€é…ç½®
  global_settings:
    algorithm: "weighted_round_robin"    # åŠ æƒè½®è¯¢
    health_check_interval: 30           # å¥åº·æ£€æŸ¥é—´éš”
    failure_threshold: 3                # å¤±è´¥é˜ˆå€¼
    recovery_threshold: 2               # æ¢å¤é˜ˆå€¼
    
  # Nginxå‰ç«¯è´Ÿè½½å‡è¡¡
  nginx_proxy:
    upstream_servers:
      - server: "127.0.0.1:8000"
        weight: 3                       # ä¸»æœåŠ¡æƒé‡3
        max_fails: 2
        fail_timeout: 30
        
      - server: "127.0.0.1:8001"
        weight: 2                       # å¤‡ç”¨æœåŠ¡æƒé‡2
        max_fails: 2
        fail_timeout: 30
        
    # è¿æ¥æ± é…ç½®
    connection_pool:
      keepalive: 32                     # ä¿æŒè¿æ¥æ•°
      keepalive_requests: 100           # æ¯è¿æ¥æœ€å¤§è¯·æ±‚æ•°
      keepalive_timeout: 60             # è¿æ¥è¶…æ—¶æ—¶é—´
      
  # APIç½‘å…³è·¯ç”±
  api_gateway:
    # ASRæœåŠ¡è´Ÿè½½å‡è¡¡
    asr_services:
      algorithm: "least_connections"    # æœ€å°‘è¿æ¥æ•°
      instances:
        - endpoint: "http://localhost:8100"
          weight: 2
          max_concurrent: 10
          
        - endpoint: "http://localhost:8101"
          weight: 1
          max_concurrent: 5
          
    # LLMæœåŠ¡è´Ÿè½½å‡è¡¡
    llm_services:
      algorithm: "response_time"        # å“åº”æ—¶é—´ä¼˜å…ˆ
      instances:
        - endpoint: "http://localhost:11434"  # æœ¬åœ°LLM
          weight: 4
          priority: "high"
          max_concurrent: 8
          
        - endpoint: "https://dashscope.aliyuncs.com"  # è¿œç¨‹LLM
          weight: 1
          priority: "low"
          max_concurrent: 3
          
    # TTSæœåŠ¡è´Ÿè½½å‡è¡¡
    tts_services:
      algorithm: "weighted_round_robin"
      instances:
        - endpoint: "http://localhost:5000"   # æœ¬åœ°Edge-TTS
          weight: 4
          priority: "high"
          max_concurrent: 15
          
        - endpoint: "https://tts-api.xfyun.cn"  # è¿œç¨‹TTS
          weight: 1
          priority: "low"
          max_concurrent: 5
```

---

## ğŸ”„ **æ™ºèƒ½è·¯ç”±ç®—æ³•**

### **å¤šç»´åº¦è·¯ç”±å†³ç­–**

```python
# intelligent_router.py
import asyncio
import time
from typing import Dict, List, Optional
from dataclasses import dataclass
from enum import Enum

class LoadBalanceAlgorithm(Enum):
    ROUND_ROBIN = "round_robin"
    WEIGHTED_ROUND_ROBIN = "weighted_round_robin"
    LEAST_CONNECTIONS = "least_connections"
    RESPONSE_TIME = "response_time"
    RESOURCE_BASED = "resource_based"

@dataclass
class ServiceInstance:
    endpoint: str
    weight: int
    priority: str
    max_concurrent: int
    current_connections: int = 0
    avg_response_time: float = 0.0
    error_rate: float = 0.0
    cpu_usage: float = 0.0
    memory_usage: float = 0.0
    is_healthy: bool = True

class IntelligentRouter:
    def __init__(self):
        self.instances: Dict[str, List[ServiceInstance]] = {}
        self.request_counts: Dict[str, int] = {}
        self.response_times: Dict[str, List[float]] = {}
        
    def register_service(self, service_name: str, instances: List[ServiceInstance]):
        """æ³¨å†ŒæœåŠ¡å®ä¾‹"""
        self.instances[service_name] = instances
        self.request_counts[service_name] = 0
        self.response_times[service_name] = []
        
    async def route_request(
        self, 
        service_name: str, 
        request_context: Dict,
        algorithm: LoadBalanceAlgorithm = LoadBalanceAlgorithm.WEIGHTED_ROUND_ROBIN
    ) -> Optional[ServiceInstance]:
        """æ™ºèƒ½è·¯ç”±è¯·æ±‚"""
        
        instances = self.instances.get(service_name, [])
        if not instances:
            return None
            
        # è¿‡æ»¤å¥åº·å®ä¾‹
        healthy_instances = [inst for inst in instances if inst.is_healthy]
        if not healthy_instances:
            return None
            
        # æ ¹æ®ç®—æ³•é€‰æ‹©å®ä¾‹
        if algorithm == LoadBalanceAlgorithm.WEIGHTED_ROUND_ROBIN:
            return self._weighted_round_robin(service_name, healthy_instances)
        elif algorithm == LoadBalanceAlgorithm.LEAST_CONNECTIONS:
            return self._least_connections(healthy_instances)
        elif algorithm == LoadBalanceAlgorithm.RESPONSE_TIME:
            return self._response_time_based(healthy_instances)
        elif algorithm == LoadBalanceAlgorithm.RESOURCE_BASED:
            return self._resource_based(healthy_instances, request_context)
        else:
            return self._round_robin(service_name, healthy_instances)
            
    def _weighted_round_robin(self, service_name: str, instances: List[ServiceInstance]) -> ServiceInstance:
        """åŠ æƒè½®è¯¢ç®—æ³•"""
        total_weight = sum(inst.weight for inst in instances)
        request_count = self.request_counts[service_name]
        
        # è®¡ç®—å½“å‰åº”è¯¥é€‰æ‹©çš„å®ä¾‹
        current_weight = request_count % total_weight
        cumulative_weight = 0
        
        for instance in instances:
            cumulative_weight += instance.weight
            if current_weight < cumulative_weight:
                self.request_counts[service_name] += 1
                return instance
                
        return instances[0]
        
    def _least_connections(self, instances: List[ServiceInstance]) -> ServiceInstance:
        """æœ€å°‘è¿æ¥æ•°ç®—æ³•"""
        return min(instances, key=lambda x: x.current_connections)
        
    def _response_time_based(self, instances: List[ServiceInstance]) -> ServiceInstance:
        """å“åº”æ—¶é—´ä¼˜å…ˆç®—æ³•"""
        # ä¼˜å…ˆé€‰æ‹©å“åº”æ—¶é—´æœ€çŸ­çš„å®ä¾‹
        return min(instances, key=lambda x: x.avg_response_time)
        
    def _resource_based(self, instances: List[ServiceInstance], context: Dict) -> ServiceInstance:
        """åŸºäºèµ„æºä½¿ç”¨ç‡çš„æ™ºèƒ½è·¯ç”±"""
        
        def calculate_score(instance: ServiceInstance) -> float:
            """è®¡ç®—å®ä¾‹å¾—åˆ†ï¼ˆè¶Šä½è¶Šå¥½ï¼‰"""
            # åŸºç¡€å¾—åˆ†
            score = 0.0
            
            # CPUä½¿ç”¨ç‡æƒé‡ (30%)
            score += instance.cpu_usage * 0.3
            
            # å†…å­˜ä½¿ç”¨ç‡æƒé‡ (25%)
            score += instance.memory_usage * 0.25
            
            # å½“å‰è¿æ¥æ•°æƒé‡ (20%)
            connection_ratio = instance.current_connections / instance.max_concurrent
            score += connection_ratio * 0.2
            
            # å“åº”æ—¶é—´æƒé‡ (15%)
            normalized_response_time = min(instance.avg_response_time / 1000, 1.0)
            score += normalized_response_time * 0.15
            
            # é”™è¯¯ç‡æƒé‡ (10%)
            score += instance.error_rate * 0.1
            
            # ä¼˜å…ˆçº§è°ƒæ•´
            if instance.priority == "high":
                score *= 0.8
            elif instance.priority == "low":
                score *= 1.2
                
            return score
            
        # é€‰æ‹©å¾—åˆ†æœ€ä½çš„å®ä¾‹
        return min(instances, key=calculate_score)
        
    async def update_instance_metrics(self, service_name: str, endpoint: str, metrics: Dict):
        """æ›´æ–°å®ä¾‹æŒ‡æ ‡"""
        instances = self.instances.get(service_name, [])
        for instance in instances:
            if instance.endpoint == endpoint:
                instance.avg_response_time = metrics.get('response_time', instance.avg_response_time)
                instance.error_rate = metrics.get('error_rate', instance.error_rate)
                instance.cpu_usage = metrics.get('cpu_usage', instance.cpu_usage)
                instance.memory_usage = metrics.get('memory_usage', instance.memory_usage)
                instance.current_connections = metrics.get('connections', instance.current_connections)
                break
                
    async def health_check(self):
        """å¥åº·æ£€æŸ¥"""
        for service_name, instances in self.instances.items():
            for instance in instances:
                try:
                    # æ‰§è¡Œå¥åº·æ£€æŸ¥
                    start_time = time.time()
                    # è¿™é‡Œåº”è¯¥å®é™…è°ƒç”¨å¥åº·æ£€æŸ¥æ¥å£
                    # response = await self.http_client.get(f"{instance.endpoint}/health")
                    response_time = (time.time() - start_time) * 1000
                    
                    instance.is_healthy = True  # response.status_code == 200
                    instance.avg_response_time = response_time
                    
                except Exception as e:
                    instance.is_healthy = False
                    print(f"å¥åº·æ£€æŸ¥å¤±è´¥ {instance.endpoint}: {e}")
```

### **åŠ¨æ€æƒé‡è°ƒæ•´**

```python
# dynamic_weight_adjuster.py
class DynamicWeightAdjuster:
    def __init__(self, router: IntelligentRouter):
        self.router = router
        self.adjustment_interval = 60  # 60ç§’è°ƒæ•´ä¸€æ¬¡
        
    async def start_adjustment_loop(self):
        """å¯åŠ¨åŠ¨æ€æƒé‡è°ƒæ•´å¾ªç¯"""
        while True:
            await self.adjust_weights()
            await asyncio.sleep(self.adjustment_interval)
            
    async def adjust_weights(self):
        """åŠ¨æ€è°ƒæ•´æƒé‡"""
        for service_name, instances in self.router.instances.items():
            await self._adjust_service_weights(service_name, instances)
            
    async def _adjust_service_weights(self, service_name: str, instances: List[ServiceInstance]):
        """è°ƒæ•´ç‰¹å®šæœåŠ¡çš„æƒé‡"""
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        total_score = 0
        for instance in instances:
            if instance.is_healthy:
                # æ€§èƒ½å¾—åˆ†ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
                performance_score = self._calculate_performance_score(instance)
                total_score += performance_score
                
        # é‡æ–°åˆ†é…æƒé‡
        for instance in instances:
            if instance.is_healthy and total_score > 0:
                performance_score = self._calculate_performance_score(instance)
                # åŸºäºæ€§èƒ½è°ƒæ•´æƒé‡
                new_weight = max(1, int((performance_score / total_score) * 10))
                instance.weight = new_weight
            else:
                instance.weight = 0  # ä¸å¥åº·çš„å®ä¾‹æƒé‡ä¸º0
                
    def _calculate_performance_score(self, instance: ServiceInstance) -> float:
        """è®¡ç®—æ€§èƒ½å¾—åˆ†"""
        # å“åº”æ—¶é—´å¾—åˆ†ï¼ˆå“åº”æ—¶é—´è¶ŠçŸ­å¾—åˆ†è¶Šé«˜ï¼‰
        response_score = max(0, 1000 - instance.avg_response_time) / 1000
        
        # èµ„æºä½¿ç”¨å¾—åˆ†ï¼ˆä½¿ç”¨ç‡è¶Šä½å¾—åˆ†è¶Šé«˜ï¼‰
        resource_score = max(0, 200 - instance.cpu_usage - instance.memory_usage) / 200
        
        # è¿æ¥æ•°å¾—åˆ†ï¼ˆè¿æ¥æ•°è¶Šå°‘å¾—åˆ†è¶Šé«˜ï¼‰
        connection_ratio = instance.current_connections / instance.max_concurrent
        connection_score = max(0, 1 - connection_ratio)
        
        # é”™è¯¯ç‡å¾—åˆ†ï¼ˆé”™è¯¯ç‡è¶Šä½å¾—åˆ†è¶Šé«˜ï¼‰
        error_score = max(0, 1 - instance.error_rate)
        
        # ç»¼åˆå¾—åˆ†
        total_score = (
            response_score * 0.3 +
            resource_score * 0.3 +
            connection_score * 0.2 +
            error_score * 0.2
        )
        
        return total_score
```

---

## ğŸ³ **å®¹å™¨åŒ–è´Ÿè½½å‡è¡¡éƒ¨ç½²**

### **å¤šå®ä¾‹Docker Composeé…ç½®**

```yaml
# docker-compose-load-balanced.yml
version: '3.8'

services:
  # Nginxè´Ÿè½½å‡è¡¡å™¨
  nginx-lb:
    image: nginx:alpine
    container_name: xiaozhi-nginx-lb
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/conf.d:/etc/nginx/conf.d
    depends_on:
      - xiaozhi-server-1
      - xiaozhi-server-2
    restart: unless-stopped
    networks:
      - xiaozhi-network

  # ä¸»æœåŠ¡å®ä¾‹1
  xiaozhi-server-1:
    image: xiaozhi-esp32-server:latest
    container_name: xiaozhi-server-1
    ports:
      - "8000:8000"
    environment:
      - SERVER_ID=server-1
      - REDIS_URL=redis://xiaozhi-redis:6379
      - DATABASE_URL=mysql://xiaozhi-db:3306/xiaozhi
      - INSTANCE_WEIGHT=3
    volumes:
      - ./config:/app/config
      - ./logs:/app/logs
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1.5G
    restart: unless-stopped
    networks:
      - xiaozhi-network

  # ä¸»æœåŠ¡å®ä¾‹2
  xiaozhi-server-2:
    image: xiaozhi-esp32-server:latest
    container_name: xiaozhi-server-2
    ports:
      - "8001:8000"
    environment:
      - SERVER_ID=server-2
      - REDIS_URL=redis://xiaozhi-redis:6379
      - DATABASE_URL=mysql://xiaozhi-db:3306/xiaozhi
      - INSTANCE_WEIGHT=2
    volumes:
      - ./config:/app/config
      - ./logs:/app/logs
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1.5G
        reservations:
          cpus: '0.5'
          memory: 1G
    restart: unless-stopped
    networks:
      - xiaozhi-network

  # ASRæœåŠ¡å®ä¾‹1
  xiaozhi-asr-1:
    image: xiaozhi-asr:latest
    container_name: xiaozhi-asr-1
    ports:
      - "8100:8000"
    environment:
      - ASR_MODEL=SenseVoiceStream
      - INSTANCE_ID=asr-1
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
    restart: unless-stopped
    networks:
      - xiaozhi-network

  # ASRæœåŠ¡å®ä¾‹2
  xiaozhi-asr-2:
    image: xiaozhi-asr:latest
    container_name: xiaozhi-asr-2
    ports:
      - "8101:8000"
    environment:
      - ASR_MODEL=SenseVoiceStream
      - INSTANCE_ID=asr-2
    deploy:
      resources:
        limits:
          cpus: '0.8'
          memory: 800M
    restart: unless-stopped
    networks:
      - xiaozhi-network

  # æœ¬åœ°LLMæœåŠ¡
  xiaozhi-llm-local:
    image: ollama/ollama:latest
    container_name: xiaozhi-llm-local
    ports:
      - "11434:11434"
    volumes:
      - ./models:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
    restart: unless-stopped
    networks:
      - xiaozhi-network

  # æœ¬åœ°TTSæœåŠ¡
  xiaozhi-tts-local:
    build:
      context: .
      dockerfile: Dockerfile.edge-tts
    container_name: xiaozhi-tts-local
    ports:
      - "5000:5000"
    volumes:
      - ./tts_cache:/tmp/tts_cache
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
    restart: unless-stopped
    networks:
      - xiaozhi-network

  # å…±äº«æ•°æ®åº“
  xiaozhi-db:
    image: mysql:8.0
    container_name: xiaozhi-db
    environment:
      - MYSQL_ROOT_PASSWORD=xiaozhi123
      - MYSQL_DATABASE=xiaozhi
    volumes:
      - ./mysql_data:/var/lib/mysql
      - ./mysql_config/my.cnf:/etc/mysql/my.cnf
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    restart: unless-stopped
    networks:
      - xiaozhi-network

  # å…±äº«Redis
  xiaozhi-redis:
    image: redis:7-alpine
    container_name: xiaozhi-redis
    command: redis-server --maxmemory 512mb --maxmemory-policy allkeys-lru
    volumes:
      - ./redis_data:/data
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    restart: unless-stopped
    networks:
      - xiaozhi-network

networks:
  xiaozhi-network:
    driver: bridge
```

### **Nginxè´Ÿè½½å‡è¡¡é…ç½®**

```nginx
# nginx/nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    
    # æ—¥å¿—æ ¼å¼
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time"';
    
    access_log /var/log/nginx/access.log main;
    
    # åŸºç¡€é…ç½®
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    
    # Gzipå‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;
    
    # ä¸Šæ¸¸æœåŠ¡å™¨å®šä¹‰
    upstream xiaozhi_backend {
        least_conn;  # æœ€å°‘è¿æ¥æ•°ç®—æ³•
        
        server xiaozhi-server-1:8000 weight=3 max_fails=2 fail_timeout=30s;
        server xiaozhi-server-2:8000 weight=2 max_fails=2 fail_timeout=30s;
        
        keepalive 32;
    }
    
    upstream xiaozhi_asr {
        least_conn;
        
        server xiaozhi-asr-1:8000 weight=2 max_fails=2 fail_timeout=30s;
        server xiaozhi-asr-2:8000 weight=1 max_fails=2 fail_timeout=30s;
        
        keepalive 16;
    }
    
    upstream xiaozhi_llm {
        ip_hash;  # ä¼šè¯ä¿æŒ
        
        server xiaozhi-llm-local:11434 weight=4 max_fails=1 fail_timeout=10s;
        # è¿œç¨‹LLMä½œä¸ºå¤‡ä»½
        # server remote-llm-api:443 weight=1 max_fails=3 fail_timeout=60s backup;
        
        keepalive 8;
    }
    
    upstream xiaozhi_tts {
        least_conn;
        
        server xiaozhi-tts-local:5000 weight=4 max_fails=1 fail_timeout=10s;
        # è¿œç¨‹TTSä½œä¸ºå¤‡ä»½
        # server remote-tts-api:443 weight=1 max_fails=3 fail_timeout=60s backup;
        
        keepalive 16;
    }
    
    # ä¸»æœåŠ¡å™¨é…ç½®
    server {
        listen 80;
        server_name localhost;
        
        # ä¸»APIè·¯ç”±
        location / {
            proxy_pass http://xiaozhi_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # è¿æ¥å’Œè¶…æ—¶è®¾ç½®
            proxy_connect_timeout 5s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
            
            # ç¼“å†²è®¾ç½®
            proxy_buffering on;
            proxy_buffer_size 4k;
            proxy_buffers 8 4k;
            
            # å¥åº·æ£€æŸ¥
            proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
            proxy_next_upstream_tries 2;
            proxy_next_upstream_timeout 3s;
        }
        
        # ASRæœåŠ¡è·¯ç”±
        location /asr/ {
            proxy_pass http://xiaozhi_asr/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            
            # ASRç‰¹æ®Šé…ç½®
            proxy_connect_timeout 3s;
            proxy_send_timeout 30s;
            proxy_read_timeout 30s;
            
            # ç¦ç”¨ç¼“å†²ä»¥æ”¯æŒæµå¼å¤„ç†
            proxy_buffering off;
            proxy_request_buffering off;
        }
        
        # LLMæœåŠ¡è·¯ç”±
        location /llm/ {
            proxy_pass http://xiaozhi_llm/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            
            # LLMç‰¹æ®Šé…ç½®
            proxy_connect_timeout 5s;
            proxy_send_timeout 120s;
            proxy_read_timeout 120s;
            
            # æ”¯æŒæµå¼å“åº”
            proxy_buffering off;
            proxy_cache off;
        }
        
        # TTSæœåŠ¡è·¯ç”±
        location /tts/ {
            proxy_pass http://xiaozhi_tts/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            
            # TTSç‰¹æ®Šé…ç½®
            proxy_connect_timeout 3s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
            
            # éŸ³é¢‘æ–‡ä»¶ç¼“å­˜
            proxy_cache tts_cache;
            proxy_cache_valid 200 1h;
            proxy_cache_key "$request_uri$request_body";
        }
        
        # WebSocketæ”¯æŒ
        location /ws/ {
            proxy_pass http://xiaozhi_backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            
            # WebSocketç‰¹æ®Šé…ç½®
            proxy_connect_timeout 7d;
            proxy_send_timeout 7d;
            proxy_read_timeout 7d;
        }
        
        # å¥åº·æ£€æŸ¥ç«¯ç‚¹
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
        
        # çŠ¶æ€ç›‘æ§
        location /nginx_status {
            stub_status on;
            access_log off;
            allow 127.0.0.1;
            deny all;
        }
    }
    
    # ç¼“å­˜é…ç½®
    proxy_cache_path /var/cache/nginx/tts levels=1:2 keys_zone=tts_cache:10m max_size=1g inactive=1h use_temp_path=off;
}
```

---

## ğŸ“Š **æ€§èƒ½æå‡é¢„æœŸ**

### **è´Ÿè½½å‡è¡¡æ•ˆæœå¯¹æ¯”**

| æŒ‡æ ‡ | å•å®ä¾‹éƒ¨ç½² | è´Ÿè½½å‡è¡¡éƒ¨ç½² | æ”¹å–„å¹…åº¦ |
|------|------------|--------------|----------|
| **æœ€å¤§å¹¶å‘è®¾å¤‡** | 10å° | 30-50å° | **+300-400%** |
| **å¹³å‡å“åº”æ—¶é—´** | 2000-4000ms | 500-1000ms | **-60-75%** |
| **ç³»ç»Ÿå¯ç”¨æ€§** | 95% | 99.5% | **+4.5%** |
| **æ•…éšœæ¢å¤æ—¶é—´** | 5-10åˆ†é’Ÿ | 30-60ç§’ | **-90%** |
| **èµ„æºåˆ©ç”¨ç‡** | 30% | 75-85% | **+150%** |
| **æ‰©å±•èƒ½åŠ›** | æ—  | æ°´å¹³æ‰©å±• | **æ— é™** |

### **å…·ä½“æ”¹å–„æ½œåŠ›åˆ†æ**

```yaml
improvement_analysis:
  # CPUåˆ©ç”¨ç‡ä¼˜åŒ–
  cpu_optimization:
    current_usage: "< 5%"
    optimized_usage: "60-80%"
    improvement: "+1500%"
    methods:
      - "å¤šå®ä¾‹å¹¶è¡Œå¤„ç†"
      - "æ™ºèƒ½ä»»åŠ¡åˆ†å‘"
      - "CPUäº²å’Œæ€§ç»‘å®š"
      
  # å†…å­˜åˆ©ç”¨ç‡ä¼˜åŒ–
  memory_optimization:
    current_usage: "45% (ä¸»æœåŠ¡)"
    optimized_usage: "75-85%"
    improvement: "+80%"
    methods:
      - "å†…å­˜æ± å…±äº«"
      - "ç¼“å­˜ç­–ç•¥ä¼˜åŒ–"
      - "åƒåœ¾å›æ”¶è°ƒä¼˜"
      
  # ç½‘ç»œååé‡ä¼˜åŒ–
  network_optimization:
    current_throughput: "ä½"
    optimized_throughput: "é«˜"
    improvement: "+200-300%"
    methods:
      - "è¿æ¥å¤ç”¨"
      - "è¯·æ±‚ç®¡é“åŒ–"
      - "å‹ç¼©ä¼ è¾“"
      
  # æœåŠ¡å¯é æ€§æå‡
  reliability_improvement:
    single_point_failure: "æ¶ˆé™¤"
    auto_failover: "å¯ç”¨"
    health_monitoring: "å®æ—¶"
    improvement: "+400%"
```

---

## ğŸ”§ **å®æ–½æ­¥éª¤**

### **é˜¶æ®µ1: åŸºç¡€è´Ÿè½½å‡è¡¡ (1-2å¤©)**

```bash
#!/bin/bash
# phase1_basic_lb.sh

echo "=== é˜¶æ®µ1: åŸºç¡€è´Ÿè½½å‡è¡¡éƒ¨ç½² ==="

# 1. åˆ›å»ºNginxé…ç½®
mkdir -p nginx/conf.d
cp nginx.conf nginx/
cp default.conf nginx/conf.d/

# 2. ä¿®æ”¹Docker Compose
cp docker-compose.yml docker-compose.backup.yml
cp docker-compose-load-balanced.yml docker-compose.yml

# 3. å¯åŠ¨è´Ÿè½½å‡è¡¡æœåŠ¡
docker-compose down
docker-compose up -d nginx-lb xiaozhi-server-1 xiaozhi-server-2

# 4. éªŒè¯è´Ÿè½½å‡è¡¡
echo "éªŒè¯è´Ÿè½½å‡è¡¡..."
for i in {1..10}; do
    curl -s http://localhost/health | grep -o "server-[12]"
done

echo "é˜¶æ®µ1å®Œæˆï¼"
```

### **é˜¶æ®µ2: æœåŠ¡åˆ†ç¦» (2-3å¤©)**

```bash
#!/bin/bash
# phase2_service_separation.sh

echo "=== é˜¶æ®µ2: æœåŠ¡åˆ†ç¦»éƒ¨ç½² ==="

# 1. éƒ¨ç½²ç‹¬ç«‹ASRæœåŠ¡
docker-compose up -d xiaozhi-asr-1 xiaozhi-asr-2

# 2. éƒ¨ç½²æœ¬åœ°LLMæœåŠ¡
docker-compose up -d xiaozhi-llm-local

# 3. éƒ¨ç½²æœ¬åœ°TTSæœåŠ¡
docker-compose up -d xiaozhi-tts-local

# 4. æ›´æ–°Nginxé…ç½®
docker-compose restart nginx-lb

# 5. éªŒè¯æœåŠ¡åˆ†ç¦»
echo "éªŒè¯ASRæœåŠ¡..."
curl -s http://localhost/asr/health

echo "éªŒè¯LLMæœåŠ¡..."
curl -s http://localhost/llm/health

echo "éªŒè¯TTSæœåŠ¡..."
curl -s http://localhost/tts/health

echo "é˜¶æ®µ2å®Œæˆï¼"
```

### **é˜¶æ®µ3: æ™ºèƒ½è·¯ç”± (3-4å¤©)**

```bash
#!/bin/bash
# phase3_intelligent_routing.sh

echo "=== é˜¶æ®µ3: æ™ºèƒ½è·¯ç”±éƒ¨ç½² ==="

# 1. éƒ¨ç½²APIç½‘å…³
docker build -t xiaozhi-api-gateway -f Dockerfile.gateway .
docker-compose up -d xiaozhi-api-gateway

# 2. é…ç½®æ™ºèƒ½è·¯ç”±
cp intelligent_router.py services/
cp dynamic_weight_adjuster.py services/

# 3. å¯åŠ¨ç›‘æ§æœåŠ¡
docker-compose up -d xiaozhi-monitor

# 4. éªŒè¯æ™ºèƒ½è·¯ç”±
echo "éªŒè¯æ™ºèƒ½è·¯ç”±..."
python test_intelligent_routing.py

echo "é˜¶æ®µ3å®Œæˆï¼"
```

---

## ğŸ“ˆ **ç›‘æ§å’Œè°ƒä¼˜**

### **å…³é”®æ€§èƒ½æŒ‡æ ‡ (KPI)**

```yaml
monitoring_kpis:
  # è´Ÿè½½å‡è¡¡æŒ‡æ ‡
  load_balancing:
    - metric: "request_distribution_ratio"
      target: "æŒ‰æƒé‡åˆ†é… Â±5%"
      alert_threshold: "åå·® > 10%"
      
    - metric: "instance_health_status"
      target: "æ‰€æœ‰å®ä¾‹å¥åº·"
      alert_threshold: "ä»»ä¸€å®ä¾‹ä¸å¥åº·"
      
    - metric: "failover_time"
      target: "< 30ç§’"
      alert_threshold: "> 60ç§’"
      
  # æ€§èƒ½æŒ‡æ ‡
  performance:
    - metric: "avg_response_time"
      target: "< 500ms"
      alert_threshold: "> 1000ms"
      
    - metric: "concurrent_connections"
      target: "30-50ä¸ªè®¾å¤‡"
      alert_threshold: "> 60ä¸ªè®¾å¤‡"
      
    - metric: "error_rate"
      target: "< 1%"
      alert_threshold: "> 5%"
      
  # èµ„æºåˆ©ç”¨ç‡
  resource_utilization:
    - metric: "cpu_usage"
      target: "60-80%"
      alert_threshold: "> 90%"
      
    - metric: "memory_usage"
      target: "70-85%"
      alert_threshold: "> 95%"
      
    - metric: "network_bandwidth"
      target: "< 80%"
      alert_threshold: "> 90%"
```

### **è‡ªåŠ¨åŒ–è°ƒä¼˜è„šæœ¬**

```python
# auto_tuning.py
import asyncio
import json
import time
from typing import Dict, List

class AutoTuner:
    def __init__(self):
        self.metrics_history = []
        self.tuning_rules = self.load_tuning_rules()
        
    def load_tuning_rules(self) -> Dict:
        """åŠ è½½è°ƒä¼˜è§„åˆ™"""
        return {
            "cpu_high": {
                "condition": "cpu_usage > 85%",
                "actions": [
                    "increase_instance_count",
                    "reduce_worker_threads",
                    "enable_cpu_throttling"
                ]
            },
            "memory_high": {
                "condition": "memory_usage > 90%",
                "actions": [
                    "clear_cache",
                    "restart_heavy_services",
                    "reduce_buffer_size"
                ]
            },
            "response_slow": {
                "condition": "avg_response_time > 1000ms",
                "actions": [
                    "switch_to_local_models",
                    "increase_cache_size",
                    "optimize_database_queries"
                ]
            },
            "high_error_rate": {
                "condition": "error_rate > 5%",
                "actions": [
                    "restart_failing_services",
                    "switch_to_backup_providers",
                    "reduce_concurrent_requests"
                ]
            }
        }
        
    async def monitor_and_tune(self):
        """ç›‘æ§å¹¶è‡ªåŠ¨è°ƒä¼˜"""
        while True:
            try:
                # æ”¶é›†æŒ‡æ ‡
                metrics = await self.collect_metrics()
                self.metrics_history.append(metrics)
                
                # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
                if len(self.metrics_history) > 100:
                    self.metrics_history = self.metrics_history[-100:]
                
                # åˆ†æå¹¶æ‰§è¡Œè°ƒä¼˜
                await self.analyze_and_tune(metrics)
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
                await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                print(f"è‡ªåŠ¨è°ƒä¼˜é”™è¯¯: {e}")
                await asyncio.sleep(30)
                
    async def collect_metrics(self) -> Dict:
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        # è¿™é‡Œåº”è¯¥å®é™…æ”¶é›†æŒ‡æ ‡
        # ç¤ºä¾‹æŒ‡æ ‡
        return {
            "timestamp": time.time(),
            "cpu_usage": 75.0,
            "memory_usage": 80.0,
            "avg_response_time": 800.0,
            "error_rate": 2.0,
            "concurrent_connections": 25,
            "instance_health": {
                "xiaozhi-server-1": True,
                "xiaozhi-server-2": True,
                "xiaozhi-asr-1": True,
                "xiaozhi-asr-2": False  # ç¤ºä¾‹ï¼šASR-2ä¸å¥åº·
            }
        }
        
    async def analyze_and_tune(self, metrics: Dict):
        """åˆ†ææŒ‡æ ‡å¹¶æ‰§è¡Œè°ƒä¼˜"""
        for rule_name, rule in self.tuning_rules.items():
            if self.evaluate_condition(rule["condition"], metrics):
                print(f"è§¦å‘è°ƒä¼˜è§„åˆ™: {rule_name}")
                for action in rule["actions"]:
                    await self.execute_action(action, metrics)
                    
    def evaluate_condition(self, condition: str, metrics: Dict) -> bool:
        """è¯„ä¼°è°ƒä¼˜æ¡ä»¶"""
        # ç®€åŒ–çš„æ¡ä»¶è¯„ä¼°
        if "cpu_usage > 85%" in condition:
            return metrics["cpu_usage"] > 85
        elif "memory_usage > 90%" in condition:
            return metrics["memory_usage"] > 90
        elif "avg_response_time > 1000ms" in condition:
            return metrics["avg_response_time"] > 1000
        elif "error_rate > 5%" in condition:
            return metrics["error_rate"] > 5
        return False
        
    async def execute_action(self, action: str, metrics: Dict):
        """æ‰§è¡Œè°ƒä¼˜åŠ¨ä½œ"""
        print(f"æ‰§è¡Œè°ƒä¼˜åŠ¨ä½œ: {action}")
        
        if action == "increase_instance_count":
            await self.scale_up_instances()
        elif action == "clear_cache":
            await self.clear_system_cache()
        elif action == "restart_heavy_services":
            await self.restart_services(["xiaozhi-server-1"])
        elif action == "switch_to_local_models":
            await self.switch_to_local_models()
        # ... å…¶ä»–åŠ¨ä½œå®ç°
        
    async def scale_up_instances(self):
        """æ‰©å±•å®ä¾‹æ•°é‡"""
        # å®ç°å®ä¾‹æ‰©å±•é€»è¾‘
        pass
        
    async def clear_system_cache(self):
        """æ¸…ç†ç³»ç»Ÿç¼“å­˜"""
        # å®ç°ç¼“å­˜æ¸…ç†é€»è¾‘
        pass
        
    async def restart_services(self, services: List[str]):
        """é‡å¯æœåŠ¡"""
        # å®ç°æœåŠ¡é‡å¯é€»è¾‘
        pass
        
    async def switch_to_local_models(self):
        """åˆ‡æ¢åˆ°æœ¬åœ°æ¨¡å‹"""
        # å®ç°æ¨¡å‹åˆ‡æ¢é€»è¾‘
        pass

# å¯åŠ¨è‡ªåŠ¨è°ƒä¼˜
if __name__ == "__main__":
    tuner = AutoTuner()
    asyncio.run(tuner.monitor_and_tune())
```

---

## âœ… **éƒ¨ç½²æ£€æŸ¥æ¸…å•**

### **éƒ¨ç½²å‰å‡†å¤‡**
- [ ] ç¡®è®¤ç¡¬ä»¶èµ„æºå……è¶³ (4æ ¸8GB)
- [ ] å¤‡ä»½ç°æœ‰é…ç½®å’Œæ•°æ®
- [ ] å‡†å¤‡Nginxé…ç½®æ–‡ä»¶
- [ ] å‡†å¤‡å¤šå®ä¾‹Dockeré…ç½®

### **éƒ¨ç½²æ­¥éª¤**
- [ ] é˜¶æ®µ1: éƒ¨ç½²åŸºç¡€è´Ÿè½½å‡è¡¡
- [ ] é˜¶æ®µ2: å®æ–½æœåŠ¡åˆ†ç¦»
- [ ] é˜¶æ®µ3: é…ç½®æ™ºèƒ½è·¯ç”±
- [ ] é…ç½®ç›‘æ§å’Œå‘Šè­¦
- [ ] éƒ¨ç½²è‡ªåŠ¨è°ƒä¼˜ç³»ç»Ÿ

### **éƒ¨ç½²åéªŒè¯**
- [ ] è´Ÿè½½åˆ†å‘æ­£å¸¸å·¥ä½œ
- [ ] æ•…éšœè½¬ç§»æœºåˆ¶æ­£å¸¸
- [ ] æ€§èƒ½æŒ‡æ ‡è¾¾åˆ°é¢„æœŸ
- [ ] ç›‘æ§ç³»ç»Ÿæ­£å¸¸è¿è¡Œ
- [ ] è‡ªåŠ¨è°ƒä¼˜åŠŸèƒ½æ­£å¸¸

**é¢„æœŸæ•ˆæœ**: è®¾å¤‡æ”¯æ’‘èƒ½åŠ›ä»10å°æå‡åˆ°30-50å°ï¼Œæ”¹å–„æ½œåŠ›è¾¾åˆ°**300-400%**ï¼