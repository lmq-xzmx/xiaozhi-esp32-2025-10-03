#!/usr/bin/env python3
"""
TTS (Text-to-Speech) å¾®æœåŠ¡
æ”¯æŒå¹¶å‘å¤„ç†ã€éŸ³é¢‘ç¼“å­˜ã€å¤šå¼•æ“è´Ÿè½½å‡è¡¡å’Œæµå¼ä¼ è¾“
æé™ä¼˜åŒ–ç‰ˆæœ¬ï¼šæ”¯æŒ80-100å°è®¾å¤‡å¹¶å‘
"""

import asyncio
import logging
import time
import hashlib
import json
import io
import base64
from typing import List, Dict, Optional, Any, AsyncGenerator
from dataclasses import dataclass
from enum import Enum
import aiofiles
import redis.asyncio as redis
from fastapi import FastAPI, HTTPException, BackgroundTasks, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
import uvicorn
from pydantic import BaseModel
import edge_tts
import azure.cognitiveservices.speech as speechsdk
from concurrent.futures import ThreadPoolExecutor
import tempfile
import os

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TTSEngine(Enum):
    """TTSå¼•æ“æšä¸¾"""
    EDGE_TTS = "edge_tts"
    AZURE_TTS = "azure_tts"
    XUNFEI_TTS = "xunfei_tts"
    LOCAL_TTS = "local_tts"
    HUOSHAN_TTS = "huoshan_tts"  # ç«å±±å¼•æ“TTS (åŒæµå¼)

@dataclass
class TTSVoice:
    """TTSè¯­éŸ³é…ç½®"""
    engine: TTSEngine
    voice_id: str
    language: str
    gender: str
    name: str
    sample_rate: int = 24000
    quality: str = "high"
    speed: float = 1.0
    pitch: float = 0.0
    volume: float = 1.0

class TTSRequest(BaseModel):
    """TTSè¯·æ±‚æ¨¡å‹"""
    session_id: str
    text: str
    voice_id: Optional[str] = None
    language: str = "zh-CN"
    speed: float = 1.0
    pitch: float = 0.0
    volume: float = 1.0
    format: str = "opus"  # æé™ä¼˜åŒ–ï¼šé»˜è®¤ä½¿ç”¨opusæ ¼å¼æé«˜å‹ç¼©æ•ˆç‡
    sample_rate: int = 24000
    stream: bool = False
    cache_enabled: bool = True
    priority: int = 2  # 1=é«˜ä¼˜å…ˆçº§, 2=ä¸­ä¼˜å…ˆçº§, 3=ä½ä¼˜å…ˆçº§

class TTSResponse(BaseModel):
    """TTSå“åº”æ¨¡å‹"""
    session_id: str
    audio_data: Optional[str] = None  # base64ç¼–ç çš„éŸ³é¢‘æ•°æ®
    audio_url: Optional[str] = None
    duration: float
    format: str
    sample_rate: int
    file_size: int
    processing_time: float
    cached: bool = False
    voice_id: str
    engine: str

class TTSCache:
    """TTSéŸ³é¢‘ç¼“å­˜ç®¡ç†å™¨ - æé™ä¼˜åŒ–ç‰ˆæœ¬"""
    
    def __init__(self, redis_client, cache_dir: str = "/tmp/tts_cache"):
        self.redis_client = redis_client
        self.cache_dir = cache_dir
        # æé™ä¼˜åŒ–ï¼šä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        self.cache_ttl = int(os.getenv("TTS_CACHE_TTL", "7200"))  # 2å°æ—¶TTL
        self.max_file_size = int(os.getenv("TTS_MAX_FILE_SIZE", "20")) * 1024 * 1024  # 20MB
        self.compression_enabled = os.getenv("TTS_ENABLE_COMPRESSION", "true").lower() == "true"
        self.preload_enabled = os.getenv("TTS_ENABLE_PRELOAD", "true").lower() == "true"
        
        # åˆ›å»ºç¼“å­˜ç›®å½•
        os.makedirs(cache_dir, exist_ok=True)
        
        # æé™ä¼˜åŒ–ï¼šæ‰©å±•é¢„ç¼“å­˜å¸¸ç”¨çŸ­è¯­
        self.common_phrases = {
            "greetings": ["ä½ å¥½", "æ—©ä¸Šå¥½", "ä¸‹åˆå¥½", "æ™šä¸Šå¥½", "æ¬¢è¿ä½¿ç”¨", "å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡"],
            "confirmations": ["å¥½çš„", "æ˜ç™½äº†", "æ”¶åˆ°", "æ²¡é—®é¢˜", "å¯ä»¥", "å½“ç„¶"],
            "questions": ["æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„å—", "è¿˜æœ‰å…¶ä»–é—®é¢˜å—", "éœ€è¦æˆ‘åšä»€ä¹ˆ", "è¯·é—®æ‚¨éœ€è¦ä»€ä¹ˆ"],
            "responses": ["æ­£åœ¨å¤„ç†", "è¯·ç¨ç­‰", "é©¬ä¸Šä¸ºæ‚¨å¤„ç†", "æ­£åœ¨ä¸ºæ‚¨æŸ¥è¯¢", "å¤„ç†å®Œæˆ"],
            "errors": ["æŠ±æ­‰", "å‡ºç°äº†é—®é¢˜", "è¯·é‡è¯•", "ç³»ç»Ÿç¹å¿™", "è¿æ¥å¤±è´¥"],
            "numbers": [str(i) for i in range(100)],  # 0-99æ•°å­—
            "time": ["ç‚¹", "åˆ†", "ç§’", "ä¸Šåˆ", "ä¸‹åˆ", "ä»Šå¤©", "æ˜å¤©", "æ˜¨å¤©"],
        }
        
        # æé™ä¼˜åŒ–ï¼šç¼“å­˜ç»Ÿè®¡
        self.cache_stats = {
            "hits": 0,
            "misses": 0,
            "preload_hits": 0,
            "total_size": 0,
        }

    def generate_cache_key(self, text: str, voice_id: str, speed: float, pitch: float, volume: float) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = f"{text}:{voice_id}:{speed}:{pitch}:{volume}"
        return f"tts_cache:{hashlib.md5(content.encode()).hexdigest()}"
    
    async def get_cached_audio(self, cache_key: str) -> Optional[Dict]:
        """è·å–ç¼“å­˜éŸ³é¢‘"""
        try:
            cached_info = await self.redis_client.get(cache_key)
            if cached_info:
                info = json.loads(cached_info)
                file_path = info["file_path"]
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if os.path.exists(file_path):
                    async with aiofiles.open(file_path, 'rb') as f:
                        audio_data = await f.read()
                    
                    info["audio_data"] = audio_data
                    return info
                else:
                    # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ é™¤ç¼“å­˜è®°å½•
                    await self.redis_client.delete(cache_key)
        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜éŸ³é¢‘å¤±è´¥: {e}")
        return None
    
    async def cache_audio(self, cache_key: str, audio_data: bytes, metadata: Dict):
        """ç¼“å­˜éŸ³é¢‘æ•°æ®"""
        try:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            if len(audio_data) > self.max_file_size:
                logger.warning(f"éŸ³é¢‘æ–‡ä»¶è¿‡å¤§ï¼Œè·³è¿‡ç¼“å­˜: {len(audio_data)} bytes")
                return
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            file_name = f"{cache_key.split(':')[-1]}.{metadata['format']}"
            file_path = os.path.join(self.cache_dir, file_name)
            
            async with aiofiles.open(file_path, 'wb') as f:
                await f.write(audio_data)
            
            # ä¿å­˜å…ƒæ•°æ®åˆ°Redis
            cache_info = {
                "file_path": file_path,
                "duration": metadata["duration"],
                "format": metadata["format"],
                "sample_rate": metadata["sample_rate"],
                "file_size": len(audio_data),
                "voice_id": metadata["voice_id"],
                "engine": metadata["engine"],
                "timestamp": time.time()
            }
            
            await self.redis_client.setex(cache_key, self.cache_ttl, json.dumps(cache_info))
            logger.info(f"éŸ³é¢‘ç¼“å­˜æˆåŠŸ: {file_path}")
            
        except Exception as e:
            logger.error(f"ç¼“å­˜éŸ³é¢‘å¤±è´¥: {e}")
    
    async def cleanup_expired_cache(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        try:
            # è·å–æ‰€æœ‰ç¼“å­˜é”®
            keys = await self.redis_client.keys("tts_cache:*")
            
            for key in keys:
                cached_info = await self.redis_client.get(key)
                if cached_info:
                    info = json.loads(cached_info)
                    file_path = info["file_path"]
                    
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ é™¤Redisè®°å½•
                    if not os.path.exists(file_path):
                        await self.redis_client.delete(key)
                        logger.info(f"æ¸…ç†æ— æ•ˆç¼“å­˜: {key}")
        except Exception as e:
            logger.error(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
    
    async def preload_common_cache(self, engine):
        """P0ä¼˜åŒ–ï¼šé¢„åŠ è½½å¸¸ç”¨çŸ­è¯­ç¼“å­˜"""
        try:
            logger.info("å¼€å§‹é¢„åŠ è½½TTSå¸¸ç”¨çŸ­è¯­ç¼“å­˜...")
            preload_count = 0
            
            # é»˜è®¤è¯­éŸ³é…ç½®
            default_voices = ["zh-CN-XiaoxiaoNeural", "zh-CN-YunxiNeural"]
            
            for category, phrases in self.common_phrases.items():
                for phrase in phrases:
                    for voice_id in default_voices:
                        try:
                            # æ£€æŸ¥æ˜¯å¦å·²ç¼“å­˜
                            cache_key = self.generate_cache_key(phrase, voice_id, 1.0, 0.0, 1.0)
                            cached = await self.get_cached_audio(cache_key)
                            
                            if not cached:
                                # ç”ŸæˆéŸ³é¢‘
                                audio_data = await engine.synthesize(phrase, voice_id)
                                
                                # ç¼“å­˜éŸ³é¢‘
                                metadata = {
                                    "duration": len(audio_data) / 48000,  # ä¼°ç®—æ—¶é•¿
                                    "format": "mp3",
                                    "sample_rate": 24000,
                                    "voice_id": voice_id,
                                    "engine": "edge_tts",
                                    "category": category,
                                    "preloaded": True
                                }
                                await self.cache_audio(cache_key, audio_data, metadata)
                                preload_count += 1
                                
                                # é¿å…è¿‡å¿«è¯·æ±‚
                                await asyncio.sleep(0.1)
                                
                        except Exception as e:
                            logger.warning(f"é¢„ç¼“å­˜å¤±è´¥ '{phrase}' ({voice_id}): {e}")
                            continue
            
            logger.info(f"TTSé¢„ç¼“å­˜å®Œæˆï¼Œå…±é¢„ç”Ÿæˆ {preload_count} ä¸ªéŸ³é¢‘æ–‡ä»¶")
            
        except Exception as e:
            logger.error(f"TTSé¢„ç¼“å­˜å¤±è´¥: {e}")
    
    def is_common_phrase(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºå¸¸ç”¨çŸ­è¯­"""
        text = text.strip()
        for phrases in self.common_phrases.values():
            if text in phrases:
                return True
        return False

class EdgeTTSEngine:
    """Edge TTSå¼•æ“"""
    
    def __init__(self):
        self.voices = {}
        self.load_voices()
    
    def load_voices(self):
        """åŠ è½½å¯ç”¨è¯­éŸ³"""
        # å¸¸ç”¨ä¸­æ–‡è¯­éŸ³
        self.voices = {
            "zh-CN-XiaoxiaoNeural": TTSVoice(TTSEngine.EDGE_TTS, "zh-CN-XiaoxiaoNeural", "zh-CN", "female", "æ™“æ™“"),
            "zh-CN-YunxiNeural": TTSVoice(TTSEngine.EDGE_TTS, "zh-CN-YunxiNeural", "zh-CN", "male", "äº‘å¸Œ"),
            "zh-CN-YunyangNeural": TTSVoice(TTSEngine.EDGE_TTS, "zh-CN-YunyangNeural", "zh-CN", "male", "äº‘æ‰¬"),
            "zh-CN-XiaoyiNeural": TTSVoice(TTSEngine.EDGE_TTS, "zh-CN-XiaoyiNeural", "zh-CN", "female", "æ™“ä¼Š"),
        }
    
    async def synthesize(self, text: str, voice_id: str, speed: float = 1.0, pitch: float = 0.0, volume: float = 1.0) -> bytes:
        """åˆæˆè¯­éŸ³"""
        try:
            # æ„å»ºSSML
            rate = f"{int((speed - 1) * 100):+d}%"
            pitch_str = f"{int(pitch * 50):+d}Hz"
            volume_str = f"{int(volume * 100)}%"
            
            communicate = edge_tts.Communicate(text, voice_id, rate=rate, pitch=pitch_str, volume=volume_str)
            
            # æ”¶é›†éŸ³é¢‘æ•°æ®
            audio_data = b""
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    audio_data += chunk["data"]
            
            return audio_data
            
        except Exception as e:
            logger.error(f"Edge TTSåˆæˆå¤±è´¥: {e}")
            raise
    
    async def synthesize_stream(self, text: str, voice_id: str, speed: float = 1.0, pitch: float = 0.0, volume: float = 1.0) -> AsyncGenerator[bytes, None]:
        """æµå¼åˆæˆè¯­éŸ³"""
        try:
            # æ„å»ºSSML
            rate = f"{int((speed - 1) * 100):+d}%"
            pitch_str = f"{int(pitch * 50):+d}Hz"
            volume_str = f"{int(volume * 100)}%"
            
            communicate = edge_tts.Communicate(text, voice_id, rate=rate, pitch=pitch_str, volume=volume_str)
            
            # æµå¼è¿”å›éŸ³é¢‘æ•°æ®
            async for chunk in communicate.stream():
                if chunk["type"] == "audio":
                    yield chunk["data"]
            
        except Exception as e:
            logger.error(f"Edge TTSæµå¼åˆæˆå¤±è´¥: {e}")
            raise

class HuoshanTTSEngine:
    """ç«å±±å¼•æ“TTS - åŒæµå¼è¯­éŸ³åˆæˆ"""
    
    def __init__(self):
        # æé™ä¼˜åŒ–ï¼šä»ç¯å¢ƒå˜é‡è¯»å–ç«å±±å¼•æ“é…ç½®
        self.api_key = os.getenv("HUOSHAN_TTS_API_KEY", "")
        self.app_id = os.getenv("HUOSHAN_TTS_APP_ID", "")
        self.cluster = os.getenv("HUOSHAN_TTS_CLUSTER", "volcano_tts")
        self.voice_type = os.getenv("HUOSHAN_TTS_VOICE_TYPE", "BV700_streaming")  # åŒæµå¼
        self.enabled = bool(self.api_key and self.app_id)
        
        # æé™ä¼˜åŒ–ï¼šåŒæµå¼é…ç½®
        self.stream_enabled = True
        self.chunk_size = int(os.getenv("HUOSHAN_TTS_CHUNK_SIZE", "1024"))
        self.sample_rate = int(os.getenv("HUOSHAN_TTS_SAMPLE_RATE", "24000"))
        
        if self.enabled:
            logger.info("ğŸ”¥ ç«å±±å¼•æ“åŒæµå¼TTSå·²å¯ç”¨")
        else:
            logger.warning("âš ï¸ ç«å±±å¼•æ“TTSé…ç½®ç¼ºå¤±ï¼Œä½¿ç”¨Edge TTSä½œä¸ºå¤‡ç”¨")

    def load_voices(self):
        """åŠ è½½ç«å±±å¼•æ“è¯­éŸ³åˆ—è¡¨"""
        if not self.enabled:
            return {}
        
        return {
            "BV700_streaming": TTSVoice(
                engine=TTSEngine.HUOSHAN_TTS,
                voice_id="BV700_streaming",
                language="zh-CN",
                gender="female",
                name="ç«å±±åŒæµå¼å¥³å£°",
                sample_rate=self.sample_rate,
                quality="high"
            ),
            "BV701_streaming": TTSVoice(
                engine=TTSEngine.HUOSHAN_TTS,
                voice_id="BV701_streaming", 
                language="zh-CN",
                gender="male",
                name="ç«å±±åŒæµå¼ç”·å£°",
                sample_rate=self.sample_rate,
                quality="high"
            )
        }

    async def synthesize(self, text: str, voice_id: str, speed: float = 1.0, pitch: float = 0.0, volume: float = 1.0) -> bytes:
        """ç«å±±å¼•æ“TTSåˆæˆ - åŒæµå¼"""
        if not self.enabled:
            raise Exception("ç«å±±å¼•æ“TTSæœªé…ç½®")
        
        try:
            # æé™ä¼˜åŒ–ï¼šä½¿ç”¨åŒæµå¼API
            import requests
            
            url = f"https://openspeech.bytedance.com/api/v1/tts"
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "app": {
                    "appid": self.app_id,
                    "token": self.api_key,
                    "cluster": self.cluster
                },
                "user": {
                    "uid": "xiaozhi_user"
                },
                "audio": {
                    "voice_type": voice_id,
                    "encoding": "opus",  # æé™ä¼˜åŒ–ï¼šä½¿ç”¨opusç¼–ç 
                    "speed_ratio": speed,
                    "volume_ratio": volume,
                    "pitch_ratio": pitch,
                    "sample_rate": self.sample_rate
                },
                "request": {
                    "reqid": f"xiaozhi_{int(time.time())}",
                    "text": text,
                    "text_type": "plain",
                    "operation": "submit"
                }
            }
            
            # æé™ä¼˜åŒ–ï¼šå¼‚æ­¥è¯·æ±‚
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None, 
                lambda: requests.post(url, json=payload, headers=headers, timeout=10)
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get("code") == 3000:
                    # è·å–éŸ³é¢‘æ•°æ®
                    audio_data = base64.b64decode(result["data"])
                    return audio_data
                else:
                    raise Exception(f"ç«å±±å¼•æ“TTSé”™è¯¯: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
            else:
                raise Exception(f"ç«å±±å¼•æ“TTSè¯·æ±‚å¤±è´¥: {response.status_code}")
                
        except Exception as e:
            logger.error(f"âŒ ç«å±±å¼•æ“TTSåˆæˆå¤±è´¥: {e}")
            raise

    async def synthesize_stream(self, text: str, voice_id: str, speed: float = 1.0, pitch: float = 0.0, volume: float = 1.0) -> AsyncGenerator[bytes, None]:
        """ç«å±±å¼•æ“åŒæµå¼TTSåˆæˆ"""
        if not self.enabled:
            raise Exception("ç«å±±å¼•æ“TTSæœªé…ç½®")
        
        try:
            # æé™ä¼˜åŒ–ï¼šåŒæµå¼å®ç°
            audio_data = await self.synthesize(text, voice_id, speed, pitch, volume)
            
            # åˆ†å—æµå¼è¿”å›
            chunk_size = self.chunk_size
            for i in range(0, len(audio_data), chunk_size):
                chunk = audio_data[i:i + chunk_size]
                yield chunk
                await asyncio.sleep(0.001)  # æé™ä¼˜åŒ–ï¼šæœ€å°å»¶è¿Ÿ
                
        except Exception as e:
            logger.error(f"âŒ ç«å±±å¼•æ“åŒæµå¼TTSå¤±è´¥: {e}")
            raise

class TTSLoadBalancer:
    """TTSè´Ÿè½½å‡è¡¡å™¨ - æé™ä¼˜åŒ–ç‰ˆæœ¬"""
    
    def __init__(self):
        # æé™ä¼˜åŒ–ï¼šåŠ¨æ€å¼•æ“æƒé‡é…ç½®
        self.engines = {
            TTSEngine.HUOSHAN_TTS: {
                "weight": float(os.getenv("HUOSHAN_TTS_WEIGHT", "0.8")),  # ä¼˜å…ˆç«å±±å¼•æ“
                "max_concurrent": int(os.getenv("HUOSHAN_TTS_MAX_CONCURRENT", "60")),
                "current_load": 0,
                "total_requests": 0,
                "success_rate": 1.0,
                "avg_latency": 0.0,
                "enabled": True
            },
            TTSEngine.EDGE_TTS: {
                "weight": float(os.getenv("EDGE_TTS_WEIGHT", "0.2")),  # å¤‡ç”¨å¼•æ“
                "max_concurrent": int(os.getenv("EDGE_TTS_MAX_CONCURRENT", "40")),
                "current_load": 0,
                "total_requests": 0,
                "success_rate": 1.0,
                "avg_latency": 0.0,
                "enabled": True
            }
        }
        
        # åˆå§‹åŒ–å¼•æ“å®ä¾‹
        self.engine_instances = {
            TTSEngine.HUOSHAN_TTS: HuoshanTTSEngine(),
            TTSEngine.EDGE_TTS: EdgeTTSEngine(),
        }
        
        # æé™ä¼˜åŒ–ï¼šæ™ºèƒ½è·¯ç”±é…ç½®
        self.enable_smart_routing = os.getenv("TTS_SMART_ROUTING", "true").lower() == "true"
        self.failover_enabled = os.getenv("TTS_FAILOVER_ENABLED", "true").lower() == "true"

    def select_engine(self, voice_id: str, text_length: int = 0) -> TTSEngine:
        """æ™ºèƒ½é€‰æ‹©TTSå¼•æ“ - æé™ä¼˜åŒ–"""
        try:
            # æé™ä¼˜åŒ–ï¼šä¼˜å…ˆä½¿ç”¨ç«å±±å¼•æ“ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
            huoshan_engine = self.engine_instances[TTSEngine.HUOSHAN_TTS]
            if huoshan_engine.enabled and self.engines[TTSEngine.HUOSHAN_TTS]["enabled"]:
                huoshan_load = self.engines[TTSEngine.HUOSHAN_TTS]["current_load"]
                huoshan_max = self.engines[TTSEngine.HUOSHAN_TTS]["max_concurrent"]
                
                if huoshan_load < huoshan_max:
                    return TTSEngine.HUOSHAN_TTS
            
            # å¤‡ç”¨ï¼šä½¿ç”¨Edge TTS
            edge_load = self.engines[TTSEngine.EDGE_TTS]["current_load"]
            edge_max = self.engines[TTSEngine.EDGE_TTS]["max_concurrent"]
            
            if edge_load < edge_max:
                return TTSEngine.EDGE_TTS
            
            # æé™ä¼˜åŒ–ï¼šå¦‚æœéƒ½æ»¡è½½ï¼Œé€‰æ‹©è´Ÿè½½è¾ƒä½çš„
            if self.enable_smart_routing:
                huoshan_ratio = huoshan_load / huoshan_max if huoshan_max > 0 else 1.0
                edge_ratio = edge_load / edge_max if edge_max > 0 else 1.0
                
                return TTSEngine.HUOSHAN_TTS if huoshan_ratio <= edge_ratio else TTSEngine.EDGE_TTS
            
            # é»˜è®¤è¿”å›ç«å±±å¼•æ“
            return TTSEngine.HUOSHAN_TTS
            
        except Exception as e:
            logger.warning(f"âš ï¸ å¼•æ“é€‰æ‹©å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤: {e}")
            return TTSEngine.EDGE_TTS


    
    def select_engine(self, voice_id: str, text_length: int = 0) -> TTSEngine:
        """P0ä¼˜åŒ–ï¼šæ™ºèƒ½é€‰æ‹©æœ€ä½³TTSå¼•æ“"""
        # 1. ä¼˜å…ˆä½¿ç”¨æœ¬åœ°Edge TTSï¼ˆ80%æƒé‡ï¼‰
        if text_length <= 500:  # çŸ­æ–‡æœ¬ä¼˜å…ˆæœ¬åœ°
            edge_stats = self.engine_stats[TTSEngine.EDGE_TTS]
            if edge_stats.get("success_rate", 0.9) > 0.9:  # æˆåŠŸç‡>90%
                return TTSEngine.EDGE_TTS
        
        # 2. æ ¹æ®å¼•æ“å¥åº·çŠ¶æ€é€‰æ‹©
        available_engines = []
        for engine, stats in self.engine_stats.items():
            success_rate = 1.0 - (stats["total_errors"] / max(stats["total_requests"], 1))
            if success_rate > 0.8:  # æˆåŠŸç‡>80%
                available_engines.append((engine, self.engine_priority[engine]))
        
        # 3. æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œé€‰æ‹©æœ€é«˜ä¼˜å…ˆçº§çš„å¯ç”¨å¼•æ“
        if available_engines:
            available_engines.sort(key=lambda x: x[1])  # æŒ‰ä¼˜å…ˆçº§æ’åº
            return available_engines[0][0]
        
        # 4. å…œåº•ï¼šè¿”å›Edge TTS
        return TTSEngine.EDGE_TTS
    
    def get_engine(self, engine_type: TTSEngine):
        """è·å–å¼•æ“å®ä¾‹"""
        return self.engines.get(engine_type)
    
    def update_stats(self, engine_type: TTSEngine, processing_time: float, success: bool):
        """æ›´æ–°å¼•æ“ç»Ÿè®¡"""
        stats = self.engine_stats[engine_type]
        stats["total_requests"] += 1
        stats["total_time"] += processing_time
        
        if not success:
            stats["total_errors"] += 1

class TTSService:
    """æé™ä¼˜åŒ–çš„TTSæœåŠ¡ï¼Œæ”¯æŒ80-100å°è®¾å¤‡å¹¶å‘"""
    
    def __init__(self, max_concurrent: int = None):
        # æé™ä¼˜åŒ–ï¼šä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        self.max_concurrent = max_concurrent or int(os.getenv("TTS_MAX_CONCURRENT", "80"))  # æå‡åˆ°80
        self.queue_size = int(os.getenv("TTS_QUEUE_SIZE", "200"))  # æå‡é˜Ÿåˆ—å¤§å°
        self.worker_threads = int(os.getenv("TTS_WORKER_THREADS", "8"))  # å¢åŠ å·¥ä½œçº¿ç¨‹
        self.batch_size = int(os.getenv("TTS_BATCH_SIZE", "16"))  # æ‰¹å¤„ç†å¤§å°
        self.batch_timeout = float(os.getenv("TTS_BATCH_TIMEOUT", "100")) / 1000  # 100ms
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.load_balancer = TTSLoadBalancer()
        self.redis_client = None
        self.cache = None
        
        # æé™ä¼˜åŒ–ï¼šå¤šä¼˜å…ˆçº§é˜Ÿåˆ—
        self.high_priority_queue = asyncio.Queue(maxsize=self.queue_size // 3)
        self.medium_priority_queue = asyncio.Queue(maxsize=self.queue_size // 2)
        self.low_priority_queue = asyncio.Queue(maxsize=self.queue_size)
        
        # æé™ä¼˜åŒ–ï¼šçº¿ç¨‹æ± é…ç½®
        self.thread_pool = ThreadPoolExecutor(
            max_workers=self.worker_threads,
            thread_name_prefix="TTS-Worker"
        )
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "cache_hits": 0,
            "average_processing_time": 0.0,
            "current_concurrent": 0,
            "max_concurrent": self.max_concurrent,
            "queue_sizes": {"high": 0, "medium": 0, "low": 0},
            "engine_stats": {}
        }
        
        # å¯åŠ¨åå°ä»»åŠ¡
        asyncio.create_task(self.process_queue())
        asyncio.create_task(self.performance_monitor())
        asyncio.create_task(self.cleanup_task())


    async def init_redis(self, redis_url: str = "redis://localhost:6379"):
        """åˆå§‹åŒ–Redisè¿æ¥"""
        try:
            self.redis_client = redis.from_url(redis_url)
            await self.redis_client.ping()
            self.cache = TTSCache(self.redis_client)
            logger.info("Redisè¿æ¥æˆåŠŸ")
        except Exception as e:
            logger.error(f"Redisè¿æ¥å¤±è´¥: {e}")
    
    async def process_queue(self):
        """å¤„ç†é˜Ÿåˆ—ä»»åŠ¡"""
        while True:
            try:
                # æ£€æŸ¥å¹¶å‘é™åˆ¶
                if self.current_concurrent >= self.max_concurrent:
                    await asyncio.sleep(0.1)
                    continue
                
                # ä»ä¼˜å…ˆçº§é˜Ÿåˆ—è·å–è¯·æ±‚
                request = await self.get_next_request()
                if request:
                    asyncio.create_task(self.process_single_request(request))
                else:
                    await asyncio.sleep(0.01)
                    
            except Exception as e:
                logger.error(f"é˜Ÿåˆ—å¤„ç†é”™è¯¯: {e}")
                await asyncio.sleep(0.1)
    
    async def get_next_request(self) -> Optional[TTSRequest]:
        """ä»ä¼˜å…ˆçº§é˜Ÿåˆ—è·å–ä¸‹ä¸€ä¸ªè¯·æ±‚"""
        timeout = 0.1
        
        for queue in [self.high_priority_queue, self.medium_priority_queue, self.low_priority_queue]:
            try:
                request = await asyncio.wait_for(queue.get(), timeout=timeout)
                return request
            except asyncio.TimeoutError:
                continue
        
        return None
    
    async def process_single_request(self, request: TTSRequest):
        """å¤„ç†å•ä¸ªTTSè¯·æ±‚"""
        self.current_concurrent += 1
        start_time = time.time()
        
        try:
            result = await self.synthesize_speech(request)
            processing_time = time.time() - start_time
            
            # æ›´æ–°ç»Ÿè®¡
            self.total_requests += 1
            self.total_processing_time += processing_time
            
            # è¿™é‡Œåº”è¯¥å°†ç»“æœå‘é€ç»™å®¢æˆ·ç«¯ï¼ˆç®€åŒ–å®ç°ï¼‰
            logger.info(f"TTSå¤„ç†å®Œæˆ: {request.session_id}, è€—æ—¶: {processing_time:.3f}s")
            
        except Exception as e:
            logger.error(f"TTSå¤„ç†å¤±è´¥: {e}")
        finally:
            self.current_concurrent -= 1
    
    async def synthesize_speech(self, request: TTSRequest) -> TTSResponse:
        """P0ä¼˜åŒ–ï¼šåˆæˆè¯­éŸ³ - æœ¬åœ°ä¼˜å…ˆç­–ç•¥"""
        start_time = time.time()
        
        try:
            # ç”Ÿæˆç¼“å­˜é”®
            voice_id = request.voice_id or "zh-CN-XiaoxiaoNeural"
            cache_key = None
            
            if request.cache_enabled and self.cache:
                cache_key = self.cache.generate_cache_key(
                    request.text,
                    voice_id,
                    request.speed,
                    request.pitch,
                    request.volume
                )
                
                # P0ä¼˜åŒ–ï¼šä¼˜å…ˆæ£€æŸ¥å¸¸ç”¨çŸ­è¯­ç¼“å­˜
                if self.cache.is_common_phrase(request.text):
                    cached_audio = await self.cache.get_cached_audio(cache_key)
                    if cached_audio:
                        self.cache_hits += 1
                        logger.info(f"å¸¸ç”¨çŸ­è¯­ç¼“å­˜å‘½ä¸­: {request.text}")
                        return TTSResponse(
                            session_id=request.session_id,
                            audio_data=base64.b64encode(cached_audio["audio_data"]).decode(),
                            duration=cached_audio["duration"],
                            format=cached_audio["format"],
                            sample_rate=cached_audio["sample_rate"],
                            file_size=cached_audio["file_size"],
                            processing_time=time.time() - start_time,
                            cached=True,
                            voice_id=voice_id,
                            engine=cached_audio["engine"]
                        )
                
                # æ£€æŸ¥æ™®é€šç¼“å­˜
                cached_audio = await self.cache.get_cached_audio(cache_key)
                if cached_audio:
                    self.cache_hits += 1
                    logger.info(f"TTSç¼“å­˜å‘½ä¸­: {request.text[:20]}...")
                    return TTSResponse(
                        session_id=request.session_id,
                        audio_data=base64.b64encode(cached_audio["audio_data"]).decode(),
                        duration=cached_audio["duration"],
                        format=cached_audio["format"],
                        sample_rate=cached_audio["sample_rate"],
                        file_size=cached_audio["file_size"],
                        processing_time=time.time() - start_time,
                        cached=True,
                        voice_id=voice_id,
                        engine=cached_audio["engine"]
                    )
            
            # P0ä¼˜åŒ–ï¼šæ™ºèƒ½é€‰æ‹©TTSå¼•æ“ï¼ˆæœ¬åœ°ä¼˜å…ˆï¼‰
            text_length = len(request.text)
            engine_type = self.load_balancer.select_engine(voice_id, text_length)
            engine = self.load_balancer.get_engine(engine_type)
            
            if not engine:
                raise Exception(f"ä¸æ”¯æŒçš„TTSå¼•æ“: {engine_type}")
            
            # åˆæˆè¯­éŸ³
            audio_data = await engine.synthesize(
                request.text,
                voice_id,
                request.speed,
                request.pitch,
                request.volume
            )
            
            processing_time = time.time() - start_time
            
            # è®¡ç®—éŸ³é¢‘æ—¶é•¿ï¼ˆç®€åŒ–å®ç°ï¼‰
            duration = len(audio_data) / (request.sample_rate * 2)  # å‡è®¾16ä½éŸ³é¢‘
            
            # æ›´æ–°å¼•æ“ç»Ÿè®¡
            self.load_balancer.update_stats(engine_type, processing_time, True)
            
            # ç¼“å­˜éŸ³é¢‘
            if request.cache_enabled and self.cache:
                metadata = {
                    "duration": duration,
                    "format": request.format,
                    "sample_rate": request.sample_rate,
                    "voice_id": voice_id,
                    "engine": engine_type.value
                }
                await self.cache.cache_audio(cache_key, audio_data, metadata)
            
            return TTSResponse(
                session_id=request.session_id,
                audio_data=base64.b64encode(audio_data).decode(),
                duration=duration,
                format=request.format,
                sample_rate=request.sample_rate,
                file_size=len(audio_data),
                processing_time=processing_time,
                cached=False,
                voice_id=voice_id,
                engine=engine_type.value
            )
            
        except Exception as e:
            # æ›´æ–°å¼•æ“ç»Ÿè®¡
            if 'engine_type' in locals():
                self.load_balancer.update_stats(engine_type, 0, False)
            
            logger.error(f"è¯­éŸ³åˆæˆå¤±è´¥: {e}")
            raise
    
    async def add_request(self, request: TTSRequest):
        """æ·»åŠ TTSè¯·æ±‚åˆ°ä¼˜å…ˆçº§é˜Ÿåˆ—"""
        if request.priority == 1:
            await self.high_priority_queue.put(request)
        elif request.priority == 2:
            await self.medium_priority_queue.put(request)
        else:
            await self.low_priority_queue.put(request)
    
    async def cleanup_task(self):
        """å®šæœŸæ¸…ç†ä»»åŠ¡"""
        while True:
            try:
                await asyncio.sleep(3600)  # æ¯å°æ—¶æ‰§è¡Œä¸€æ¬¡
                if self.cache:
                    await self.cache.cleanup_expired_cache()
            except Exception as e:
                logger.error(f"æ¸…ç†ä»»åŠ¡å¤±è´¥: {e}")
    
    def get_stats(self) -> Dict:
        """è·å–æœåŠ¡ç»Ÿè®¡"""
        avg_processing_time = self.total_processing_time / max(self.total_requests, 1)
        cache_hit_rate = self.cache_hits / max(self.total_requests, 1)
        
        engine_stats = []
        for engine_type, stats in self.load_balancer.engine_stats.items():
            avg_time = stats["total_time"] / max(stats["total_requests"], 1)
            error_rate = stats["total_errors"] / max(stats["total_requests"], 1)
            
            engine_stats.append({
                "engine": engine_type.value,
                "total_requests": stats["total_requests"],
                "total_errors": stats["total_errors"],
                "error_rate": error_rate,
                "avg_processing_time": avg_time,
                "current_load": stats["current_load"],
                "max_concurrent": stats["max_concurrent"]
            })
        
        return {
            "total_requests": self.total_requests,
            "cache_hits": self.cache_hits,
            "cache_hit_rate": cache_hit_rate,
            "avg_processing_time": avg_processing_time,
            "current_concurrent": self.current_concurrent,
            "max_concurrent": self.max_concurrent,
            "queue_sizes": {
                "high_priority": self.high_priority_queue.qsize(),
                "medium_priority": self.medium_priority_queue.qsize(),
                "low_priority": self.low_priority_queue.qsize()
            },
            "engines": engine_stats
        }

# FastAPIåº”ç”¨
app = FastAPI(title="TTS Service", version="1.0.0")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€TTSæœåŠ¡å®ä¾‹ - P0ä¼˜åŒ–é…ç½®
tts_service = TTSService(max_concurrent=40)  # P0ä¼˜åŒ–ï¼šä»30æå‡åˆ°40

@app.on_event("startup")
async def startup_event():
    """å¯åŠ¨äº‹ä»¶ - P0ä¼˜åŒ–ç‰ˆæœ¬"""
    await tts_service.init_redis()
    
    # P0ä¼˜åŒ–ï¼šå¯åŠ¨æ—¶é¢„åŠ è½½å¸¸ç”¨çŸ­è¯­ç¼“å­˜
    if tts_service.cache and tts_service.load_balancer.engines:
        edge_engine = tts_service.load_balancer.get_engine(TTSEngine.EDGE_TTS)
        if edge_engine:
            await tts_service.cache.preload_common_cache(edge_engine)
            logger.info("TTSæœåŠ¡å¯åŠ¨å®Œæˆï¼Œé¢„ç¼“å­˜å·²åŠ è½½")

@app.post("/tts/synthesize", response_model=TTSResponse)
async def synthesize_speech(request: TTSRequest, background_tasks: BackgroundTasks):
    """TTSè¯­éŸ³åˆæˆAPI"""
    try:
        response = await tts_service.synthesize_speech(request)
        return response
    except Exception as e:
        logger.error(f"TTSåˆæˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/tts/synthesize_stream")
async def synthesize_speech_stream(request: TTSRequest):
    """TTSæµå¼è¯­éŸ³åˆæˆAPI - çœŸæ­£çš„æµå¼ä¼ è¾“"""
    try:
        async def audio_stream_generator():
            """éŸ³é¢‘æµç”Ÿæˆå™¨"""
            voice_id = request.voice_id or "zh-CN-XiaoxiaoNeural"
            engine_type = tts_service.load_balancer.select_engine(voice_id)
            engine = tts_service.load_balancer.get_engine(engine_type)
            
            if not engine:
                raise Exception(f"ä¸æ”¯æŒçš„TTSå¼•æ“: {engine_type}")
            
            # ä½¿ç”¨æµå¼åˆæˆ
            async for audio_chunk in engine.synthesize_stream(
                request.text,
                voice_id,
                request.speed,
                request.pitch,
                request.volume
            ):
                yield audio_chunk
        
        return StreamingResponse(
            audio_stream_generator(),
            media_type="audio/mpeg",
            headers={
                "Content-Disposition": f"attachment; filename=tts_{request.session_id}.mp3",
                "Cache-Control": "no-cache",
                "Connection": "keep-alive"
            }
        )
    except Exception as e:
        logger.error(f"TTSæµå¼åˆæˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/tts/voices")
async def get_available_voices():
    """è·å–å¯ç”¨è¯­éŸ³åˆ—è¡¨"""
    edge_engine = tts_service.load_balancer.get_engine(TTSEngine.EDGE_TTS)
    voices = []
    
    for voice_id, voice in edge_engine.voices.items():
        voices.append({
            "voice_id": voice_id,
            "name": voice.name,
            "language": voice.language,
            "gender": voice.gender,
            "engine": voice.engine.value
        })
    
    return {"voices": voices}

@app.get("/tts/stats")
async def get_stats():
    """è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
    return tts_service.get_stats()

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "service": "tts",
        "current_concurrent": tts_service.current_concurrent,
        "max_concurrent": tts_service.max_concurrent
    }

@app.get("/xiaozhi/ota/")
async def ota_version_check():
    """OTAç‰ˆæœ¬æ£€æŸ¥ç«¯ç‚¹ - ESP32è®¾å¤‡ç”¨äºæ£€æŸ¥å›ºä»¶æ›´æ–°"""
    return {
        "firmware": {
            "version": "1.0.0",
            "url": "https://api.tenclass.net/xiaozhi/ota/firmware.bin"
        },
        "server_time": {
            "timestamp": int(time.time() * 1000),  # æ¯«ç§’æ—¶é—´æˆ³
            "timezone_offset": 480  # UTC+8 (ä¸­å›½æ—¶åŒº)
        }
    }

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8003, workers=1)